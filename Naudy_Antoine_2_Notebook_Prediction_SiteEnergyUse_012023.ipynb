{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b37083d1",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    "\n",
    "<a href=\"#A6\">**Partie 4 : Prédictions**</a>\n",
    " - <a href=\"#C10\">4-1 Prédictions variable 'SiteEnergyUseWN(kBtu)/sf'</a>\n",
    " - <a href=\"#C11\">4-1-1 Baseline : Méthode Naive Mean</a>\n",
    " - <a href=\"#C12\">4-1-2 Régularisation KernelRidge</a>\n",
    " - <a href=\"#C13\">4-1-3 Régularisation Lasso</a>\n",
    " - <a href=\"#C14\">4-1-4 Régularisation ElasticNet</a>\n",
    " - <a href=\"#C15\">4-1-5 Régression KNN</a>\n",
    " - <a href=\"#C16\">4-1-6 Régression Kernel SVR</a>\n",
    " - <a href=\"#C17\">4-1-7 XGboost</a>\n",
    " - <a href=\"#C18\">4-1-8 Random Forest</a>\n",
    " - <a href=\"#C19\">4-1-9 Synthèse modèle prédictif 'SiteEnergyUseWN(kBtu)/sf'</a>\n",
    " \n",
    "<a href=\"#A7\">**Partie 5 : Comparaison avec/sans la variable 'EnergyStar'**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc2f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import time\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#estimators\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, ElasticNetCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2f9f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>CouncilDistrictCode</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking/sf</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>LargestPropertyUseTypeGFA/sf</th>\n",
       "      <th>SourceEUIWN(kBtu/sf)</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)/sf</th>\n",
       "      <th>Electricity(kBtu)/sf</th>\n",
       "      <th>NaturalGas(kBtu)/sf</th>\n",
       "      <th>TotalGHGEmissions/sf</th>\n",
       "      <th>GHGEmissionsIntensity/sf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>47.61220</td>\n",
       "      <td>-122.33799</td>\n",
       "      <td>1927</td>\n",
       "      <td>12</td>\n",
       "      <td>88434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88434</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>84.321754</td>\n",
       "      <td>44.621152</td>\n",
       "      <td>14.433962</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>47.61390</td>\n",
       "      <td>-122.33283</td>\n",
       "      <td>1926</td>\n",
       "      <td>11</td>\n",
       "      <td>83008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83008</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.980050</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>73.038352</td>\n",
       "      <td>33.866796</td>\n",
       "      <td>35.509589</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>47.61327</td>\n",
       "      <td>-122.33136</td>\n",
       "      <td>1926</td>\n",
       "      <td>8</td>\n",
       "      <td>102761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102761</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.300003</td>\n",
       "      <td>68.779805</td>\n",
       "      <td>35.389447</td>\n",
       "      <td>3.748397</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>47.65959</td>\n",
       "      <td>-122.31755</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>88592</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>58006</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.654754</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>41.461833</td>\n",
       "      <td>25.580538</td>\n",
       "      <td>15.772338</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>47.61500</td>\n",
       "      <td>-122.33081</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>67224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67224</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.200001</td>\n",
       "      <td>19.490608</td>\n",
       "      <td>19.490599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>47.65476</td>\n",
       "      <td>-122.34732</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>126823</td>\n",
       "      <td>0.327535</td>\n",
       "      <td>85284</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.695118</td>\n",
       "      <td>169.500000</td>\n",
       "      <td>47.644351</td>\n",
       "      <td>32.451685</td>\n",
       "      <td>15.192662</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>47.54425</td>\n",
       "      <td>-122.31776</td>\n",
       "      <td>1955</td>\n",
       "      <td>1</td>\n",
       "      <td>52085</td>\n",
       "      <td>0.081060</td>\n",
       "      <td>47863</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.599998</td>\n",
       "      <td>80.303768</td>\n",
       "      <td>14.069367</td>\n",
       "      <td>55.160833</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>47.68109</td>\n",
       "      <td>-122.33282</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>72000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72000</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>101.800003</td>\n",
       "      <td>44.428583</td>\n",
       "      <td>26.411389</td>\n",
       "      <td>14.224444</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>47.58831</td>\n",
       "      <td>-122.30650</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>1.016178</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>31.060942</td>\n",
       "      <td>29.466067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>47.66127</td>\n",
       "      <td>-122.31256</td>\n",
       "      <td>1962</td>\n",
       "      <td>1</td>\n",
       "      <td>68072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68072</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>1.012399</td>\n",
       "      <td>144.899994</td>\n",
       "      <td>46.727278</td>\n",
       "      <td>46.727274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BuildingType  PrimaryPropertyType   ZipCode  CouncilDistrictCode  \\\n",
       "0         0.000967             0.001735  0.001170                    7   \n",
       "1         0.000967             0.001735  0.001170                    7   \n",
       "2         0.000967             0.001332  0.001170                    7   \n",
       "3         0.000967             0.001735  0.001125                    4   \n",
       "4         0.000967             0.001332  0.001170                    7   \n",
       "...            ...                  ...       ...                  ...   \n",
       "1066      0.000967             0.001735  0.000961                    4   \n",
       "1067      0.000967             0.000785  0.000947                    2   \n",
       "1068      0.000967             0.001332  0.000988                    4   \n",
       "1069      0.000967             0.001677  0.000718                    3   \n",
       "1070      0.000988             0.000978  0.000597                    4   \n",
       "\n",
       "      Neighborhood  Latitude  Longitude  YearBuilt  NumberofFloors  \\\n",
       "0         0.000910  47.61220 -122.33799       1927              12   \n",
       "1         0.000910  47.61390 -122.33283       1926              11   \n",
       "2         0.000910  47.61327 -122.33136       1926               8   \n",
       "3         0.001072  47.65959 -122.31755       2001               6   \n",
       "4         0.000910  47.61500 -122.33081       1930               2   \n",
       "...            ...       ...        ...        ...             ...   \n",
       "1066      0.000791  47.65476 -122.34732       2014               4   \n",
       "1067      0.000898  47.54425 -122.31776       1955               1   \n",
       "1068      0.001072  47.68109 -122.33282       2013               1   \n",
       "1069      0.000898  47.58831 -122.30650       2015               3   \n",
       "1070      0.001072  47.66127 -122.31256       1962               1   \n",
       "\n",
       "      PropertyGFATotal  PropertyGFAParking/sf  PropertyGFABuilding(s)  \\\n",
       "0                88434               0.000000                   88434   \n",
       "1                83008               0.000000                   83008   \n",
       "2               102761               0.000000                  102761   \n",
       "3                88592               0.345246                   58006   \n",
       "4                67224               0.000000                   67224   \n",
       "...                ...                    ...                     ...   \n",
       "1066            126823               0.327535                   85284   \n",
       "1067             52085               0.081060                   47863   \n",
       "1068             72000               0.000000                   72000   \n",
       "1069             45000               0.000000                   45000   \n",
       "1070             68072               0.000000                   68072   \n",
       "\n",
       "      LargestPropertyUseType  LargestPropertyUseTypeGFA/sf  \\\n",
       "0                   0.001711                      1.000000   \n",
       "1                   0.001711                      0.980050   \n",
       "2                   0.001539                      1.000000   \n",
       "3                   0.001711                      0.654754   \n",
       "4                   0.000672                      1.000000   \n",
       "...                      ...                           ...   \n",
       "1066                0.001711                      0.695118   \n",
       "1067                0.000793                      1.000000   \n",
       "1068                0.001990                      1.000000   \n",
       "1069                0.001677                      1.016178   \n",
       "1070                0.000978                      1.012399   \n",
       "\n",
       "      SourceEUIWN(kBtu/sf)  SiteEnergyUseWN(kBtu)/sf  Electricity(kBtu)/sf  \\\n",
       "0               189.000000                 84.321754             44.621152   \n",
       "1               154.699997                 73.038352             33.866796   \n",
       "2               152.300003                 68.779805             35.389447   \n",
       "3               148.500000                 41.461833             25.580538   \n",
       "4                61.200001                 19.490608             19.490599   \n",
       "...                    ...                       ...                   ...   \n",
       "1066            169.500000                 47.644351             32.451685   \n",
       "1067            114.599998                 80.303768             14.069367   \n",
       "1068            101.800003                 44.428583             26.411389   \n",
       "1069             96.000000                 31.060942             29.466067   \n",
       "1070            144.899994                 46.727278             46.727274   \n",
       "\n",
       "      NaturalGas(kBtu)/sf  TotalGHGEmissions/sf  GHGEmissionsIntensity/sf  \n",
       "0               14.433962              0.002827                  0.000032  \n",
       "1               35.509589              0.002122                  0.000026  \n",
       "2                3.748397              0.002156                  0.000021  \n",
       "3               15.772338              0.001016                  0.000012  \n",
       "4                0.000000              0.000136                  0.000002  \n",
       "...                   ...                   ...                       ...  \n",
       "1066            15.192662              0.001033                  0.000008  \n",
       "1067            55.160833              0.003028                  0.000058  \n",
       "1068            14.224444              0.000940                  0.000013  \n",
       "1069             0.000000              0.000205                  0.000005  \n",
       "1070             0.000000              0.000326                  0.000005  \n",
       "\n",
       "[1071 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df33=pd.read_csv('df33.csv')\n",
    "df33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219ba71",
   "metadata": {},
   "source": [
    "# <a name=\"A6\">**Partie 4 : Prédictions**</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff850a1c",
   "metadata": {},
   "source": [
    "## <a name=\"C10\">4-1 Prédictions variable ‘SiteEnergyUseWN(kBtu)/sf</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f5409",
   "metadata": {},
   "source": [
    "## Echantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7780da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df41=df33.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c95f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformons les data en X et y ('SiteEnergyUseWN(kBtu)/sf')\n",
    "df41.dropna(axis='rows', how='any',inplace=True)\n",
    "X=df41.drop(columns=['SiteEnergyUseWN(kBtu)/sf',\n",
    "            'TotalGHGEmissions/sf',\n",
    "            'GHGEmissionsIntensity/sf'\n",
    "                    ]\n",
    "           )\n",
    "y=df41['SiteEnergyUseWN(kBtu)/sf'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5728f66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x8000 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisons les variables\n",
    "fig = plt.figure(figsize=(20, 80))\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    ax = fig.add_subplot(25,5, (feat_idx+1))\n",
    "    h = ax.hist(X.iloc[:, feat_idx], bins=50, color='steelblue', density=True, edgecolor='none')\n",
    "    ax.set_title(X.columns[feat_idx], fontsize=12)\n",
    "    plt.xticks(fontsize=12)#rotation=45,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77cb1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Découpons en train et test sample\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=42,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77354ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisons X_train et X_test\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ccab9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x8000 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisons les distributions des variables transformées\n",
    "fig = plt.figure(figsize=(20, 80))\n",
    "for feat_idx in range(X_train_std.shape[1]):\n",
    "    ax = fig.add_subplot(22,5, (feat_idx+1))\n",
    "    h = ax.hist(X_train_std[:, feat_idx], bins=50, color='steelblue', density=True, edgecolor='none')\n",
    "    ax.set_title(X.columns[feat_idx], fontsize=12)\n",
    "    plt.xticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000031e4",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdaa9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(model, param) :\n",
    "    #GridSearchCV sur le train set\n",
    "    NM = GridSearchCV(model(),param,cv=5,verbose=2) \n",
    "    NM.fit(X_train_std, y_train)\n",
    "\n",
    "    #Entraînement du modèle avec les paramètres optimum sur tous le train set\n",
    "    estNM = model(**NM.best_params_)\n",
    "    estNM.fit(X_train_std, y_train)\n",
    "\n",
    "    #Regression sur le test set\n",
    "    y_pred = estNM.predict(X_test_std)\n",
    "\n",
    "    #Compraison des scores train et test set\n",
    "    print('Régression {} train set score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "          .format(model,r2_score(y_train, estNM.predict(X_train_std)),mean_absolute_error(y_train, estNM.predict(X_train_std)),\n",
    "                  mean_squared_error(y_train, estNM.predict(X_train_std))))\n",
    "    print('Régression {} test set score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "          .format(model,r2_score(y_test, y_pred),mean_absolute_error(y_test, y_pred),\n",
    "                  mean_squared_error(y_test, y_pred)))\n",
    "    return(estNM, y_pred, NM, mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a887228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a(model,estML):\n",
    "    y_pred_t=estML.predict(X_train_std)\n",
    "\n",
    "    # Plot residuals\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    plt.scatter(y_pred_t, y_pred_t - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "    plt.scatter(y_pred, y_pred - y_test, c = \"lightgreen\", marker = \"s\", label = \"Test data\")\n",
    "    plt.hlines(y = 0, xmin = 0, xmax = 200, color = \"red\")\n",
    "    plt.xlim([0,200])\n",
    "    plt.ylim([-200,60])\n",
    "    plt.title(f'{model}')\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    \n",
    "    #plt.axis('tight')\n",
    " #   plt.show()\n",
    "    return(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6839b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b(model):\n",
    "    # Plot predictions\n",
    "    plt.scatter(y_train, y_pred_t, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "    plt.scatter(y_test, y_pred, c = \"lightgreen\", marker = \"s\", label = \"Test data\")\n",
    "    plt.plot(range(200), color = \"red\")\n",
    "    plt.xlim([0,200])\n",
    "    plt.ylim([0,200])\n",
    "    plt.ylabel(\"Predicted values\")\n",
    "    plt.xlabel(\"Real values\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70338bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_c(model, estEN):\n",
    "    # Plot important coefficients\n",
    "    coefs = pd.Series(estEN.coef_, index = X_train.columns)\n",
    "    print(f\"{model} picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  str(sum(coefs == 0)) + \" features\")\n",
    "    imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                         coefs.sort_values().tail(10)])\n",
    "    imp_coefs.plot(kind = \"barh\")\n",
    "    plt.title(f\"Coefficients in the {model}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dddbaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef(estEN,model):\n",
    "    # Plot important coefficients\n",
    "    coefs = pd.Series(estEN.coef_, index = X_train.columns)\n",
    "    print(f\"{model} picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  str(sum(coefs == 0)) + \" features\")\n",
    "    imp_coefs = coefs.sort_values()\n",
    "    #imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "    #                     coefs.sort_values().tail(10)])\n",
    "    imp_coefs.plot(kind = \"barh\")\n",
    "    plt.title(f\"Coefficients in the {model} Model\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ccce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evo(model):\n",
    "    alphas = np.logspace(-3, 6, 200)\n",
    "    coefs = []\n",
    "    for a in alphas:\n",
    "        lasso = model(alpha=a, fit_intercept=False)\n",
    "        lasso.fit(X_train_std, y_train)\n",
    "        coefs.append(lasso.coef_)\n",
    "    #plt.figure(figsize=(40,20))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(alphas, coefs)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(ax.get_xlim())#[::-1])  # reverse axis\n",
    "    #plt.xlabel('alpha',fontsize=40)\n",
    "    #plt.ylabel('weights',fontsize=40)\n",
    "    #plt.title(f'{model} coefficients as a function of the regularization',fontsize=40)\n",
    "    plt.axis('tight')\n",
    "   # plt.yticks(fontsize=30)\n",
    "   # plt.xticks(fontsize=30) \n",
    "    #plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c6cd4ba",
   "metadata": {},
   "source": [
    "## <a name=\"C11\">4-1-1 Baseline : Méthode Naive Mean</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05dd5f1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ......................................strategy=mean; total time=   0.0s\n",
      "[CV] END ......................................strategy=mean; total time=   0.0s\n",
      "[CV] END ......................................strategy=mean; total time=   0.0s\n",
      "[CV] END ......................................strategy=mean; total time=   0.0s\n",
      "[CV] END ......................................strategy=mean; total time=   0.0s\n",
      "Régression <class 'sklearn.dummy.DummyRegressor'> train set score R2: 0.00, MAE: 21.51, mean_squared_error: 787.16\n",
      "Régression <class 'sklearn.dummy.DummyRegressor'> test set score R2: -0.00, MAE: 19.93, mean_squared_error: 630.98\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estAN, y_pred, AN,mae_AN)=regression(DummyRegressor,{'strategy':['mean']})\n",
    "time_AN=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3de9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(DummyRegressor,estAN)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3d69f33",
   "metadata": {},
   "source": [
    "## <a name=\"C12\">4-1-2 Régularisation KernelRidge</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461cae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n",
      "[CV] END ..................alpha=0.001, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................alpha=0.001, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0011097524964120721, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0011097524964120721, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0012315506032928262, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0012315506032928262, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.001366716356462006, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.001366716356462006, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.001366716356462006, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.001366716356462006, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.001366716356462006, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.001366716356462006, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.001366716356462006, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.001366716356462006, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0015167168884709225, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0015167168884709225, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0016831803533309566, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0016831803533309566, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0018679135990207828, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.0018679135990207828, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0018679135990207828, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002072921779595372, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002072921779595372, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002072921779595372, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002072921779595372, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002072921779595372, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002072921779595372, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002072921779595372, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002300430119772917, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002300430119772917, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002300430119772917, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002300430119772917, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002300430119772917, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002300430119772917, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002300430119772917, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0025529080682395165, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0025529080682395165, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002833096101839324, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002833096101839324, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002833096101839324, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.002833096101839324, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.002833096101839324, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.002833096101839324, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.002833096101839324, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0031440354715915, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0031440354715915, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0031440354715915, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0031440354715915, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0031440354715915, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.0031440354715915, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.0031440354715915, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.0034891012134067737, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.0034891012134067737, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.003872038781812557, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.003872038781812557, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.003872038781812557, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.003872038781812557, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.003872038781812557, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.003872038781812557, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=0.003872038781812557, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.003872038781812557, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004297004704320844, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004297004704320844, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004297004704320844, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004297004704320844, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004297004704320844, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004297004704320844, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004297004704320844, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004768611697714469, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004768611697714469, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004768611697714469, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004768611697714469, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.004768611697714469, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.004768611697714469, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.004768611697714469, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005291978735958442, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005291978735958442, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005291978735958442, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005291978735958442, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005291978735958442, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005291978735958442, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005291978735958442, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=0.005872786613189483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005872786613189483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005872786613189483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005872786613189483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005872786613189483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.005872786613189483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.005872786613189483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.005872786613189483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00651733960488242, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00651733960488242, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00651733960488242, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00651733960488242, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00651733960488242, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00651733960488242, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00651733960488242, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.007232633896483534, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.007232633896483534, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.007232633896483534, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.007232633896483534, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.007232633896483534, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.007232633896483534, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.007232633896483534, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.008026433522257174, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.008026433522257174, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.008026433522257174, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.008026433522257174, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.008026433522257174, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.008026433522257174, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.008026433522257174, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.008026433522257174, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00890735463861044, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00890735463861044, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00890735463861044, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00890735463861044, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.00890735463861044, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.00890735463861044, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.00890735463861044, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.009884959046625586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.009884959046625586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.009884959046625586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.009884959046625586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.009884959046625586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.009884959046625586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.009884959046625586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.010969857978923836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.010969857978923836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.010969857978923836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.010969857978923836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.010969857978923836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.010969857978923836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.010969857978923836, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=0.010969857978923836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.012173827277396614, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.012173827277396614, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.012173827277396614, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.012173827277396614, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.012173827277396614, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.012173827277396614, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.012173827277396614, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.013509935211980273, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.013509935211980273, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.013509935211980273, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.013509935211980273, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.013509935211980273, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.013509935211980273, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.013509935211980273, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.014992684327860457, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.014992684327860457, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.014992684327860457, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.014992684327860457, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.014992684327860457, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.014992684327860457, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.014992684327860457, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.01663816886076129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.01663816886076129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.01663816886076129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.01663816886076129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.01663816886076129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.01663816886076129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.01663816886076129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.01663816886076129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.018464249428955443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.018464249428955443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.018464249428955443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.018464249428955443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.018464249428955443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.018464249428955443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.018464249428955443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.020490746898158472, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.020490746898158472, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.020490746898158472, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.020490746898158472, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.020490746898158472, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.020490746898158472, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.020490746898158472, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.022739657523579287, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.022739657523579287, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.022739657523579287, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.022739657523579287, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.022739657523579287, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.022739657523579287, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=0.022739657523579287, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.022739657523579287, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02523539170434766, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02523539170434766, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02523539170434766, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02523539170434766, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02523539170434766, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02523539170434766, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02523539170434766, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02800503894183631, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02800503894183631, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02800503894183631, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02800503894183631, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.02800503894183631, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.02800503894183631, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.02800503894183631, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03107866187782014, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03107866187782014, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03107866187782014, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03107866187782014, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03107866187782014, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03107866187782014, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03107866187782014, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03448962260405758, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03448962260405758, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.03448962260405758, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03448962260405758, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.03448962260405758, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.03448962260405758, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.03448962260405758, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.038274944785163134, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.038274944785163134, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.038274944785163134, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.038274944785163134, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.038274944785163134, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.038274944785163134, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.038274944785163134, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.04247571552536898, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.04247571552536898, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.04247571552536898, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.04247571552536898, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.04247571552536898, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.04247571552536898, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.04247571552536898, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.047137531341167244, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.047137531341167244, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.047137531341167244, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.047137531341167244, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END alpha=0.047137531341167244, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.047137531341167244, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=0.047137531341167244, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.047137531341167244, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05231099308056263, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05231099308056263, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05231099308056263, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05231099308056263, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05231099308056263, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05231099308056263, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05231099308056263, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05805225516094899, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05805225516094899, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05805225516094899, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05805225516094899, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.05805225516094899, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.05805225516094899, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.05805225516094899, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.06442363508721373, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.06442363508721373, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.06442363508721373, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.06442363508721373, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .alpha=0.06442363508721373, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.06442363508721373, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.06442363508721373, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.07149428986597581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07149428986597581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07149428986597581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07149428986597581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07149428986597581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07149428986597581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07149428986597581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07934096665797492, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07934096665797492, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07934096665797492, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07934096665797492, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.07934096665797492, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.07934096665797492, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.07934096665797492, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.08804883581643465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.08804883581643465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.08804883581643465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.08804883581643465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.08804883581643465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.08804883581643465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.08804883581643465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.09771241535346502, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.09771241535346502, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.09771241535346502, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.09771241535346502, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.09771241535346502, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.09771241535346502, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.09771241535346502, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.09771241535346502, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.1084365968689611, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.1084365968689611, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.1084365968689611, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.1084365968689611, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.1084365968689611, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.1084365968689611, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.1084365968689611, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.12033778407775893, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.12033778407775893, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.12033778407775893, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.12033778407775893, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.12033778407775893, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.12033778407775893, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.12033778407775893, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.13354515629298988, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.13354515629298988, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.13354515629298988, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.13354515629298988, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.13354515629298988, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.13354515629298988, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.13354515629298988, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=0.13354515629298988, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.14820207057988585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.14820207057988585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.14820207057988585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.14820207057988585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.14820207057988585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.14820207057988585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.14820207057988585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.16446761779946645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.16446761779946645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.16446761779946645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.16446761779946645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.16446761779946645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.16446761779946645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.16446761779946645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.18251834943190443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.18251834943190443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.18251834943190443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.18251834943190443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.18251834943190443, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.18251834943190443, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.18251834943190443, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.20255019392306664, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.20255019392306664, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.20255019392306664, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.20255019392306664, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.20255019392306664, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.20255019392306664, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.20255019392306664, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.20255019392306664, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.22478058335487253, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.22478058335487253, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.22478058335487253, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.22478058335487253, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.22478058335487253, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.22478058335487253, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.22478058335487253, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.24945081352303167, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.24945081352303167, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.24945081352303167, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.24945081352303167, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.24945081352303167, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.24945081352303167, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.24945081352303167, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.27682866303920667, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.27682866303920667, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.27682866303920667, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.27682866303920667, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.27682866303920667, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.27682866303920667, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=0.27682866303920667, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.27682866303920667, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3072112998861759, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3072112998861759, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3072112998861759, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3072112998861759, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3072112998861759, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3072112998861759, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3072112998861759, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.34092850697468147, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.34092850697468147, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.34092850697468147, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.34092850697468147, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .alpha=0.34092850697468147, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.34092850697468147, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.34092850697468147, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3783462617131929, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3783462617131929, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3783462617131929, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3783462617131929, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.3783462617131929, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.3783462617131929, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.3783462617131929, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.419870708444391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.419870708444391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.419870708444391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.419870708444391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.419870708444391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=0.419870708444391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.419870708444391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.419870708444391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.4659525668664682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.4659525668664682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.4659525668664682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.4659525668664682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.4659525668664682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.4659525668664682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.4659525668664682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.517092024289676, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.517092024289676, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.517092024289676, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.517092024289676, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.517092024289676, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=0.517092024289676, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=0.517092024289676, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.5738441648302398, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.5738441648302398, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.5738441648302398, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.5738441648302398, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.5738441648302398, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.5738441648302398, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=0.5738441648302398, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.5738441648302398, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.6368249944718586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.6368249944718586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.6368249944718586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.6368249944718586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.6368249944718586, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.6368249944718586, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.6368249944718586, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7067181273927491, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7067181273927491, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7067181273927491, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7067181273927491, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7067181273927491, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7067181273927491, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7067181273927491, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7842822061337682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7842822061337682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7842822061337682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7842822061337682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.7842822061337682, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.7842822061337682, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.7842822061337682, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.8703591361485166, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.8703591361485166, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.8703591361485166, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.8703591361485166, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.8703591361485166, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.8703591361485166, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.8703591361485166, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.9658832241158708, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.9658832241158708, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.9658832241158708, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.9658832241158708, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=0.9658832241158708, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=0.9658832241158708, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=0.9658832241158708, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.0718913192051276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.0718913192051276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.0718913192051276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.0718913192051276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.0718913192051276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.0718913192051276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.0718913192051276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.1895340673703196, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.1895340673703196, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.1895340673703196, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.1895340673703196, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.1895340673703196, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.1895340673703196, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=1.1895340673703196, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.1895340673703196, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.3200884008314182, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.3200884008314182, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.3200884008314182, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.3200884008314182, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.3200884008314182, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.3200884008314182, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.3200884008314182, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.4649713983072863, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.4649713983072863, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.4649713983072863, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.4649713983072863, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.4649713983072863, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.4649713983072863, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.4649713983072863, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.625755666443795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.625755666443795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.625755666443795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.625755666443795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.625755666443795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1.625755666443795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1.625755666443795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.8041864093920719, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=1.8041864093920719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.8041864093920719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.8041864093920719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1.8041864093920719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1.8041864093920719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1.8041864093920719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.0022003718155843, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.0022003718155843, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.0022003718155843, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.0022003718155843, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.0022003718155843, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.0022003718155843, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.0022003718155843, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.2219468609395236, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.2219468609395236, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.2219468609395236, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.2219468609395236, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.2219468609395236, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.2219468609395236, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.2219468609395236, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.4658110758226037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.4658110758226037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.4658110758226037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.4658110758226037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2.4658110758226037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.4658110758226037, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=2.4658110758226037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2.4658110758226037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.736439997074672, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.736439997074672, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.736439997074672, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.736439997074672, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2.736439997074672, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2.736439997074672, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2.736439997074672, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3.0367711180354604, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3.0367711180354604, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3.0367711180354604, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3.0367711180354604, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3.0367711180354604, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.0367711180354604, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3.0367711180354604, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.370064329271928, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.370064329271928, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.370064329271928, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.370064329271928, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.370064329271928, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.370064329271928, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.370064329271928, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.739937302478798, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=3.739937302478798, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.739937302478798, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.739937302478798, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3.739937302478798, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=3.739937302478798, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=3.739937302478798, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.150404757850477, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.150404757850477, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.150404757850477, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.150404757850477, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.150404757850477, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.150404757850477, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.150404757850477, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.605922041145108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.605922041145108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.605922041145108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.605922041145108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4.605922041145108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4.605922041145108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4.605922041145108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=5.1114334834401705, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=5.1114334834401705, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=5.1114334834401705, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=5.1114334834401705, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=5.1114334834401705, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.1114334834401705, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=5.1114334834401705, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=5.1114334834401705, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.672426068491977, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.672426068491977, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.672426068491977, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.672426068491977, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5.672426068491977, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5.672426068491977, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5.672426068491977, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.294988990221888, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.294988990221888, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.294988990221888, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.294988990221888, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.294988990221888, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.294988990221888, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.294988990221888, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.985879746785249, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.985879746785249, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.985879746785249, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.985879746785249, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6.985879746785249, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6.985879746785249, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6.985879746785249, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=7.752597488629465, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=7.752597488629465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=7.752597488629465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=7.752597488629465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=7.752597488629465, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7.752597488629465, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=7.752597488629465, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8.60346441668451, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8.60346441668451, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8.60346441668451, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8.60346441668451, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8.60346441668451, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=8.60346441668451, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=8.60346441668451, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=9.547716114208066, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=9.547716114208066, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=9.547716114208066, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=9.547716114208066, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=9.547716114208066, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9.547716114208066, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=9.547716114208066, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10.59560179277617, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10.59560179277617, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10.59560179277617, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10.59560179277617, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10.59560179277617, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=10.59560179277617, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=10.59560179277617, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=10.59560179277617, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11.758495540521581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11.758495540521581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11.758495540521581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11.758495540521581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11.758495540521581, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11.758495540521581, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11.758495540521581, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13.049019780144016, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13.049019780144016, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13.049019780144016, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13.049019780144016, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13.049019780144016, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13.049019780144016, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13.049019780144016, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=14.481182276745331, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=14.481182276745331, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=14.481182276745331, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=14.481182276745331, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=14.481182276745331, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=14.481182276745331, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=14.481182276745331, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=16.070528182616385, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=16.070528182616385, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=16.070528182616385, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=16.070528182616385, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=16.070528182616385, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=16.070528182616385, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=16.070528182616385, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=16.070528182616385, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17.834308769319094, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17.834308769319094, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17.834308769319094, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17.834308769319094, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17.834308769319094, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17.834308769319094, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17.834308769319094, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19.791668678535572, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19.791668678535572, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19.791668678535572, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19.791668678535572, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19.791668678535572, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19.791668678535572, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19.791668678535572, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21.96385372416547, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21.96385372416547, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21.96385372416547, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21.96385372416547, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21.96385372416547, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=21.96385372416547, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21.96385372416547, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21.96385372416547, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=24.37444150122222, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=24.37444150122222, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=24.37444150122222, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=24.37444150122222, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=24.37444150122222, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=24.37444150122222, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=24.37444150122222, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=27.04959730463137, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=27.04959730463137, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=27.04959730463137, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=27.04959730463137, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=27.04959730463137, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=27.04959730463137, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=27.04959730463137, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=30.01835813575592, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=30.01835813575592, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=30.01835813575592, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=30.01835813575592, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=30.01835813575592, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=30.01835813575592, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=30.01835813575592, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=30.01835813575592, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=33.31294787934677, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=33.31294787934677, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=33.31294787934677, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=33.31294787934677, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=33.31294787934677, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=33.31294787934677, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=33.31294787934677, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=36.96912707195032, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=36.96912707195032, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=36.96912707195032, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=36.96912707195032, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=36.96912707195032, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=36.96912707195032, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=36.96912707195032, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=41.0265810582719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=41.0265810582719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=41.0265810582719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=41.0265810582719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=41.0265810582719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=41.0265810582719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=41.0265810582719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=45.52935074866948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=45.52935074866948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=45.52935074866948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=45.52935074866948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=45.52935074866948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=45.52935074866948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=45.52935074866948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=45.52935074866948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=50.526310653356795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=50.526310653356795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=50.526310653356795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=50.526310653356795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=50.526310653356795, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=50.526310653356795, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=50.526310653356795, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=56.07169938205458, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=56.07169938205458, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=56.07169938205458, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=56.07169938205458, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=56.07169938205458, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=56.07169938205458, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=56.07169938205458, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=62.22570836730231, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=62.22570836730231, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=62.22570836730231, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=62.22570836730231, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=62.22570836730231, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=62.22570836730231, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=62.22570836730231, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=62.22570836730231, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=69.0551352016233, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=69.0551352016233, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=69.0551352016233, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=69.0551352016233, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=69.0551352016233, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=69.0551352016233, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=69.0551352016233, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=76.63410868007462, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=76.63410868007462, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=76.63410868007462, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=76.63410868007462, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=76.63410868007462, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=76.63410868007462, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=76.63410868007462, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=85.04489341802686, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=85.04489341802686, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=85.04489341802686, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=85.04489341802686, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=85.04489341802686, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=85.04489341802686, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=85.04489341802686, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=94.37878277775391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=94.37878277775391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=94.37878277775391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=94.37878277775391, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=94.37878277775391, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=94.37878277775391, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=94.37878277775391, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=104.73708979594508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=104.73708979594508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=104.73708979594508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=104.73708979594508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=104.73708979594508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=104.73708979594508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=104.73708979594508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=116.23224686798542, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=116.23224686798542, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=116.23224686798542, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=116.23224686798542, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=116.23224686798542, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=116.23224686798542, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=116.23224686798542, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=128.9890261253308, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=128.9890261253308, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=128.9890261253308, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=128.9890261253308, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=128.9890261253308, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=128.9890261253308, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=128.9890261253308, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=128.9890261253308, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=143.14589375234786, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=143.14589375234786, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=143.14589375234786, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=143.14589375234786, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=143.14589375234786, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=143.14589375234786, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=143.14589375234786, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=158.85651294280527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=158.85651294280527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=158.85651294280527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=158.85651294280527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=158.85651294280527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=158.85651294280527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=158.85651294280527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=176.2914118095948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=176.2914118095948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=176.2914118095948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=176.2914118095948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=176.2914118095948, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=176.2914118095948, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=176.2914118095948, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=195.63983435170647, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=195.63983435170647, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=195.63983435170647, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=195.63983435170647, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=195.63983435170647, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=195.63983435170647, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=195.63983435170647, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=217.11179456945052, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=217.11179456945052, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=217.11179456945052, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=217.11179456945052, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=217.11179456945052, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=217.11179456945052, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=217.11179456945052, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=240.9403560239527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=240.9403560239527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=240.9403560239527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=240.9403560239527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=240.9403560239527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=240.9403560239527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=240.9403560239527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=267.38416158399497, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=267.38416158399497, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=267.38416158399497, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=267.38416158399497, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=267.38416158399497, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=267.38416158399497, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=267.38416158399497, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=267.38416158399497, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=296.73024081888724, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=296.73024081888724, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=296.73024081888724, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=296.73024081888724, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=296.73024081888724, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=296.73024081888724, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=296.73024081888724, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=329.2971255097155, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=329.2971255097155, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=329.2971255097155, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=329.2971255097155, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=329.2971255097155, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=329.2971255097155, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=329.2971255097155, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=365.43830709572546, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=365.43830709572546, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=365.43830709572546, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=365.43830709572546, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=365.43830709572546, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=365.43830709572546, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=365.43830709572546, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=405.54607358408276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=405.54607358408276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=405.54607358408276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=405.54607358408276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=405.54607358408276, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=405.54607358408276, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=405.54607358408276, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=450.05576757004974, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=450.05576757004974, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=450.05576757004974, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=450.05576757004974, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=450.05576757004974, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=450.05576757004974, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=450.05576757004974, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=499.450511585514, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=499.450511585514, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=499.450511585514, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=499.450511585514, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=499.450511585514, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=499.450511585514, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=499.450511585514, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=554.2664520663108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=554.2664520663108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=554.2664520663108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=554.2664520663108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=554.2664520663108, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=554.2664520663108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=554.2664520663108, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=554.2664520663108, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=615.0985788580505, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=615.0985788580505, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=615.0985788580505, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=615.0985788580505, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=615.0985788580505, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=615.0985788580505, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=615.0985788580505, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=682.6071834272393, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=682.6071834272393, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=682.6071834272393, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=682.6071834272393, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=682.6071834272393, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=682.6071834272393, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=682.6071834272393, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=757.525025877192, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=757.525025877192, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=757.525025877192, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=757.525025877192, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=757.525025877192, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=757.525025877192, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=757.525025877192, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=840.6652885618333, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=840.6652885618333, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=840.6652885618333, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=840.6652885618333, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=840.6652885618333, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=840.6652885618333, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=840.6652885618333, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=840.6652885618333, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=932.9304026284696, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=932.9304026284696, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=932.9304026284696, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=932.9304026284696, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=932.9304026284696, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=932.9304026284696, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=932.9304026284696, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1035.3218432956637, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1035.3218432956637, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1035.3218432956637, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1035.3218432956637, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1035.3218432956637, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1035.3218432956637, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1035.3218432956637, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1148.9510001873086, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1148.9510001873086, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1148.9510001873086, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1148.9510001873086, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1148.9510001873086, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1148.9510001873086, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=1148.9510001873086, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1148.9510001873086, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1275.051240713013, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1275.051240713013, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1275.051240713013, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1275.051240713013, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1275.051240713013, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1275.051240713013, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1275.051240713013, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1414.991297434576, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1414.991297434576, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1414.991297434576, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1414.991297434576, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1414.991297434576, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1414.991297434576, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1414.991297434576, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1570.2901247293776, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1570.2901247293776, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1570.2901247293776, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1570.2901247293776, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1570.2901247293776, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1570.2901247293776, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1570.2901247293776, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1742.6333860096508, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=1742.6333860096508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1742.6333860096508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1742.6333860096508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=1742.6333860096508, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1742.6333860096508, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=1742.6333860096508, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1933.891750455232, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1933.891750455232, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1933.891750455232, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1933.891750455232, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=1933.891750455232, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.5, kernel=poly; total time=   0.1s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=1933.891750455232, gamma=0.5, kernel=poly; total time=   0.1s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=1933.891750455232, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=0, kernel=poly; total time=   0.1s\n",
      "[CV] END ...alpha=2146.141197858406, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2146.141197858406, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2146.141197858406, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2146.141197858406, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2146.141197858406, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=2146.141197858406, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=2146.141197858406, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2381.6855519761607, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2381.6855519761607, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2381.6855519761607, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2381.6855519761607, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2381.6855519761607, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2381.6855519761607, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=2381.6855519761607, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2381.6855519761607, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2643.0814869741084, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2643.0814869741084, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2643.0814869741084, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2643.0814869741084, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2643.0814869741084, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2643.0814869741084, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2643.0814869741084, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2933.1662783900483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2933.1662783900483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2933.1662783900483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2933.1662783900483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=2933.1662783900483, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=2933.1662783900483, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=2933.1662783900483, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3255.0885998350564, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3255.0885998350564, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3255.0885998350564, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3255.0885998350564, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3255.0885998350564, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3255.0885998350564, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3255.0885998350564, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=3612.3426997094302, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3612.3426997094302, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3612.3426997094302, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3612.3426997094302, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3612.3426997094302, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=3612.3426997094302, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=3612.3426997094302, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=3612.3426997094302, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=4008.8063288984645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=4008.8063288984645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=4008.8063288984645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=4008.8063288984645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=4008.8063288984645, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4008.8063288984645, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=4008.8063288984645, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4448.782831127585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4448.782831127585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4448.782831127585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4448.782831127585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4448.782831127585, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4448.782831127585, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4448.782831127585, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4937.047852839004, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4937.047852839004, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4937.047852839004, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4937.047852839004, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=4937.047852839004, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=4937.047852839004, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=4937.047852839004, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=4937.047852839004, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5478.901179593945, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5478.901179593945, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5478.901179593945, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5478.901179593945, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=5478.901179593945, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=5478.901179593945, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=5478.901179593945, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6080.224261649427, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6080.224261649427, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6080.224261649427, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6080.224261649427, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=6080.224261649427, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=6080.224261649427, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6080.224261649427, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=6747.5440531107, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=6747.5440531107, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=6747.5440531107, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=6747.5440531107, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=6747.5440531107, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=6747.5440531107, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........alpha=6747.5440531107, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ........alpha=6747.5440531107, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7488.10385759003, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7488.10385759003, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7488.10385759003, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7488.10385759003, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=7488.10385759003, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=7488.10385759003, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=7488.10385759003, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=8309.941949353404, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=8309.941949353404, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=8309.941949353404, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=8309.941949353404, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=8309.941949353404, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=8309.941949353404, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=8309.941949353404, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9221.97882333434, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9221.97882333434, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9221.97882333434, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9221.97882333434, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=9221.97882333434, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=9221.97882333434, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .......alpha=9221.97882333434, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=10234.114021054527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=10234.114021054527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=10234.114021054527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=10234.114021054527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=10234.114021054527, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=10234.114021054527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=10234.114021054527, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=10234.114021054527, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11357.333583431051, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11357.333583431051, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11357.333583431051, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11357.333583431051, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=11357.333583431051, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=11357.333583431051, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=11357.333583431051, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=12603.829296797274, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=12603.829296797274, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=12603.829296797274, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=12603.829296797274, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=12603.829296797274, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=12603.829296797274, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=12603.829296797274, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13987.131026472387, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13987.131026472387, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13987.131026472387, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13987.131026472387, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=13987.131026472387, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=13987.131026472387, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=13987.131026472387, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=13987.131026472387, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=15522.25357427048, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=15522.25357427048, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=15522.25357427048, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=15522.25357427048, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=15522.25357427048, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=15522.25357427048, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=15522.25357427048, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17225.859653987874, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17225.859653987874, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17225.859653987874, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17225.859653987874, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=17225.859653987874, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=17225.859653987874, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=17225.859653987874, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19116.440753857038, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19116.440753857038, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19116.440753857038, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19116.440753857038, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=19116.440753857038, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=19116.440753857038, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=19116.440753857038, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21214.51784910632, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21214.51784910632, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21214.51784910632, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=21214.51784910632, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=21214.51784910632, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=21214.51784910632, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=21214.51784910632, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=23542.864143224204, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=23542.864143224204, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=23542.864143224204, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=23542.864143224204, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=23542.864143224204, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=23542.864143224204, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=23542.864143224204, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=26126.752255633317, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=26126.752255633317, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=26126.752255633317, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=26126.752255633317, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=26126.752255633317, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=26126.752255633317, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=26126.752255633317, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=28994.22853882881, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=28994.22853882881, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=28994.22853882881, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=28994.22853882881, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=28994.22853882881, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=28994.22853882881, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=28994.22853882881, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=28994.22853882881, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=32176.417502507353, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=32176.417502507353, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=32176.417502507353, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=32176.417502507353, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=32176.417502507353, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=32176.417502507353, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=32176.417502507353, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=35707.859649004626, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=35707.859649004626, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=35707.859649004626, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=35707.859649004626, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=35707.859649004626, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=35707.859649004626, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=35707.859649004626, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=39626.88638701478, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=39626.88638701478, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=39626.88638701478, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=39626.88638701478, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=39626.88638701478, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=39626.88638701478, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=39626.88638701478, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=43976.036093027215, gamma=0.01, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=43976.036093027215, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=43976.036093027215, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=43976.036093027215, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=43976.036093027215, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=43976.036093027215, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=43976.036093027215, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=48802.515836544335, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=48802.515836544335, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=48802.515836544335, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=48802.515836544335, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=48802.515836544335, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=48802.515836544335, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=48802.515836544335, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=54158.71378079476, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=54158.71378079476, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=54158.71378079476, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=54158.71378079476, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=54158.71378079476, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=54158.71378079476, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=54158.71378079476, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=60102.76782070388, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=60102.76782070388, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=60102.76782070388, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=60102.76782070388, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=60102.76782070388, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=60102.76782070388, gamma=0.5, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=60102.76782070388, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=60102.76782070388, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=66699.19663030129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=66699.19663030129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=66699.19663030129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=66699.19663030129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=66699.19663030129, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=66699.19663030129, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=66699.19663030129, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=74019.59996915652, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=74019.59996915652, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=74019.59996915652, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=74019.59996915652, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=74019.59996915652, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=74019.59996915652, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=74019.59996915652, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=82143.43584919439, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=82143.43584919439, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=82143.43584919439, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=82143.43584919439, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=82143.43584919439, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=82143.43584919439, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=82143.43584919439, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=0, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=91158.88299750836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=91158.88299750836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=91158.88299750836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=91158.88299750836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=91158.88299750836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=91158.88299750836, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=91158.88299750836, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=91158.88299750836, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=101163.7979766207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=101163.7979766207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=101163.7979766207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=101163.7979766207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=101163.7979766207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=101163.7979766207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=101163.7979766207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=112266.77735108159, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=112266.77735108159, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=112266.77735108159, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=112266.77735108159, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=112266.77735108159, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=112266.77735108159, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=112266.77735108159, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=124588.33642950082, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=124588.33642950082, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=124588.33642950082, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=124588.33642950082, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=124588.33642950082, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=124588.33642950082, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=124588.33642950082, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=124588.33642950082, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=138262.2173764659, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=138262.2173764659, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=138262.2173764659, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=138262.2173764659, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=138262.2173764659, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=138262.2173764659, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=138262.2173764659, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=153436.84089300132, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=153436.84089300132, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=153436.84089300132, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=153436.84089300132, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=153436.84089300132, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=153436.84089300132, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=153436.84089300132, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=170276.91722258978, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=170276.91722258978, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=170276.91722258978, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=170276.91722258978, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=170276.91722258978, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=170276.91722258978, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=170276.91722258978, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=170276.91722258978, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=188965.23396912115, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=188965.23396912115, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=188965.23396912115, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=188965.23396912115, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=188965.23396912115, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=188965.23396912115, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=188965.23396912115, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=209704.64013232305, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=209704.64013232305, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=209704.64013232305, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=209704.64013232305, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=209704.64013232305, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=209704.64013232305, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=209704.64013232305, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=232720.2478960412, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=232720.2478960412, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=232720.2478960412, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=232720.2478960412, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=232720.2478960412, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=232720.2478960412, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=232720.2478960412, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=258261.87606826748, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=258261.87606826748, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=258261.87606826748, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=258261.87606826748, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=258261.87606826748, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=258261.87606826748, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=258261.87606826748, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=258261.87606826748, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=286606.7616948256, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=286606.7616948256, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=286606.7616948256, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=286606.7616948256, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=286606.7616948256, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=286606.7616948256, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=286606.7616948256, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=318062.5692794119, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=318062.5692794119, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=318062.5692794119, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=318062.5692794119, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=318062.5692794119, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=318062.5692794119, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=318062.5692794119, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=352970.73027306574, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=352970.73027306574, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=352970.73027306574, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=352970.73027306574, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ..alpha=352970.73027306574, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=352970.73027306574, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=2, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....alpha=352970.73027306574, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END .....alpha=352970.73027306574, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=391710.1490809261, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=391710.1490809261, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=391710.1490809261, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=391710.1490809261, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=391710.1490809261, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=391710.1490809261, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=391710.1490809261, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=434701.3158125035, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=434701.3158125035, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=434701.3158125035, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=434701.3158125035, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=434701.3158125035, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=434701.3158125035, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=434701.3158125035, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=482410.8704165374, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=482410.8704165374, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=482410.8704165374, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=482410.8704165374, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=482410.8704165374, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=482410.8704165374, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=482410.8704165374, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=535356.6677410719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=535356.6677410719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=535356.6677410719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=535356.6677410719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=535356.6677410719, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=535356.6677410719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=535356.6677410719, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=535356.6677410719, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=594113.3984965039, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=594113.3984965039, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=594113.3984965039, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=594113.3984965039, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=594113.3984965039, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=594113.3984965039, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=594113.3984965039, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=659318.8271333541, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=659318.8271333541, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=659318.8271333541, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=659318.8271333541, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=659318.8271333541, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=659318.8271333541, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=659318.8271333541, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=731680.7143427207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=731680.7143427207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=731680.7143427207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=731680.7143427207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=731680.7143427207, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=731680.7143427207, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......alpha=731680.7143427207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=731680.7143427207, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=811984.4993184009, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=811984.4993184009, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=811984.4993184009, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=811984.4993184009, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=811984.4993184009, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=811984.4993184009, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=811984.4993184009, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=901101.8251665037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=901101.8251665037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=901101.8251665037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=901101.8251665037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...alpha=901101.8251665037, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ....alpha=901101.8251665037, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ......alpha=901101.8251665037, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=0, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........alpha=1000000.0, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........alpha=1000000.0, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........alpha=1000000.0, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........alpha=1000000.0, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........alpha=1000000.0, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ............alpha=1000000.0, gamma=0.5, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=2, kernel=poly; total time=   0.0s\n",
      "[CV] END ..............alpha=1000000.0, gamma=2, kernel=poly; total time=   0.0s\n",
      "Régression <class 'sklearn.kernel_ridge.KernelRidge'> train set score R2: 0.89, MAE: 3.56, mean_squared_error: 87.11\n",
      "Régression <class 'sklearn.kernel_ridge.KernelRidge'> test set score R2: 0.96, MAE: 3.41, mean_squared_error: 27.63\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estKR, y_pred,KR,mae_KR)=regression(KernelRidge,{'kernel':['poly'],'alpha':np.logspace(-3, 6, 200),\n",
    "             'gamma' : [0, 0.01, 0.1, 0.5, 1, 2]})#['linear', 'poly', 'rbf']\n",
    "time_KR=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd35e7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(KernelRidge,estKR)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b87e42d",
   "metadata": {},
   "source": [
    "## <a name=\"C13\">4-1-3 Régularisation Lasso</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf1e81c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0011097524964120721; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0011097524964120721; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0011097524964120721; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0011097524964120721; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0011097524964120721; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0012315506032928262; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0012315506032928262; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0012315506032928262; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0012315506032928262; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0012315506032928262; total time=   0.0s\n",
      "[CV] END .........................alpha=0.001366716356462006; total time=   0.0s\n",
      "[CV] END .........................alpha=0.001366716356462006; total time=   0.0s\n",
      "[CV] END .........................alpha=0.001366716356462006; total time=   0.0s\n",
      "[CV] END .........................alpha=0.001366716356462006; total time=   0.0s\n",
      "[CV] END .........................alpha=0.001366716356462006; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0015167168884709225; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0015167168884709225; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0015167168884709225; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0015167168884709225; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0015167168884709225; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0016831803533309566; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0016831803533309566; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0016831803533309566; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0016831803533309566; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0016831803533309566; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018679135990207828; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018679135990207828; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018679135990207828; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018679135990207828; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018679135990207828; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002072921779595372; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002072921779595372; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002072921779595372; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002072921779595372; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002072921779595372; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002300430119772917; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002300430119772917; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002300430119772917; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002300430119772917; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002300430119772917; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0025529080682395165; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0025529080682395165; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0025529080682395165; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0025529080682395165; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0025529080682395165; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002833096101839324; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002833096101839324; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002833096101839324; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002833096101839324; total time=   0.0s\n",
      "[CV] END .........................alpha=0.002833096101839324; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0031440354715915; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0031440354715915; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0031440354715915; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0031440354715915; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0031440354715915; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0034891012134067737; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0034891012134067737; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0034891012134067737; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0034891012134067737; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0034891012134067737; total time=   0.0s\n",
      "[CV] END .........................alpha=0.003872038781812557; total time=   0.0s\n",
      "[CV] END .........................alpha=0.003872038781812557; total time=   0.0s\n",
      "[CV] END .........................alpha=0.003872038781812557; total time=   0.0s\n",
      "[CV] END .........................alpha=0.003872038781812557; total time=   0.0s\n",
      "[CV] END .........................alpha=0.003872038781812557; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004297004704320844; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004297004704320844; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004297004704320844; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004297004704320844; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004297004704320844; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004768611697714469; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004768611697714469; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004768611697714469; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004768611697714469; total time=   0.0s\n",
      "[CV] END .........................alpha=0.004768611697714469; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005291978735958442; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005291978735958442; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005291978735958442; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005291978735958442; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005291978735958442; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005872786613189483; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005872786613189483; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005872786613189483; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005872786613189483; total time=   0.0s\n",
      "[CV] END .........................alpha=0.005872786613189483; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00651733960488242; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00651733960488242; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00651733960488242; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00651733960488242; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00651733960488242; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007232633896483534; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007232633896483534; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007232633896483534; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007232633896483534; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007232633896483534; total time=   0.0s\n",
      "[CV] END .........................alpha=0.008026433522257174; total time=   0.0s\n",
      "[CV] END .........................alpha=0.008026433522257174; total time=   0.0s\n",
      "[CV] END .........................alpha=0.008026433522257174; total time=   0.0s\n",
      "[CV] END .........................alpha=0.008026433522257174; total time=   0.0s\n",
      "[CV] END .........................alpha=0.008026433522257174; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00890735463861044; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00890735463861044; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00890735463861044; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00890735463861044; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00890735463861044; total time=   0.0s\n",
      "[CV] END .........................alpha=0.009884959046625586; total time=   0.0s\n",
      "[CV] END .........................alpha=0.009884959046625586; total time=   0.0s\n",
      "[CV] END .........................alpha=0.009884959046625586; total time=   0.0s\n",
      "[CV] END .........................alpha=0.009884959046625586; total time=   0.0s\n",
      "[CV] END .........................alpha=0.009884959046625586; total time=   0.0s\n",
      "[CV] END .........................alpha=0.010969857978923836; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.010969857978923836; total time=   0.0s\n",
      "[CV] END .........................alpha=0.010969857978923836; total time=   0.0s\n",
      "[CV] END .........................alpha=0.010969857978923836; total time=   0.0s\n",
      "[CV] END .........................alpha=0.010969857978923836; total time=   0.0s\n",
      "[CV] END .........................alpha=0.012173827277396614; total time=   0.0s\n",
      "[CV] END .........................alpha=0.012173827277396614; total time=   0.0s\n",
      "[CV] END .........................alpha=0.012173827277396614; total time=   0.0s\n",
      "[CV] END .........................alpha=0.012173827277396614; total time=   0.0s\n",
      "[CV] END .........................alpha=0.012173827277396614; total time=   0.0s\n",
      "[CV] END .........................alpha=0.013509935211980273; total time=   0.0s\n",
      "[CV] END .........................alpha=0.013509935211980273; total time=   0.0s\n",
      "[CV] END .........................alpha=0.013509935211980273; total time=   0.0s\n",
      "[CV] END .........................alpha=0.013509935211980273; total time=   0.0s\n",
      "[CV] END .........................alpha=0.013509935211980273; total time=   0.0s\n",
      "[CV] END .........................alpha=0.014992684327860457; total time=   0.0s\n",
      "[CV] END .........................alpha=0.014992684327860457; total time=   0.0s\n",
      "[CV] END .........................alpha=0.014992684327860457; total time=   0.0s\n",
      "[CV] END .........................alpha=0.014992684327860457; total time=   0.0s\n",
      "[CV] END .........................alpha=0.014992684327860457; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01663816886076129; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01663816886076129; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01663816886076129; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01663816886076129; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01663816886076129; total time=   0.0s\n",
      "[CV] END .........................alpha=0.018464249428955443; total time=   0.0s\n",
      "[CV] END .........................alpha=0.018464249428955443; total time=   0.0s\n",
      "[CV] END .........................alpha=0.018464249428955443; total time=   0.0s\n",
      "[CV] END .........................alpha=0.018464249428955443; total time=   0.0s\n",
      "[CV] END .........................alpha=0.018464249428955443; total time=   0.0s\n",
      "[CV] END .........................alpha=0.020490746898158472; total time=   0.0s\n",
      "[CV] END .........................alpha=0.020490746898158472; total time=   0.0s\n",
      "[CV] END .........................alpha=0.020490746898158472; total time=   0.0s\n",
      "[CV] END .........................alpha=0.020490746898158472; total time=   0.0s\n",
      "[CV] END .........................alpha=0.020490746898158472; total time=   0.0s\n",
      "[CV] END .........................alpha=0.022739657523579287; total time=   0.0s\n",
      "[CV] END .........................alpha=0.022739657523579287; total time=   0.0s\n",
      "[CV] END .........................alpha=0.022739657523579287; total time=   0.0s\n",
      "[CV] END .........................alpha=0.022739657523579287; total time=   0.0s\n",
      "[CV] END .........................alpha=0.022739657523579287; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02523539170434766; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02523539170434766; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02523539170434766; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02523539170434766; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02523539170434766; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02800503894183631; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02800503894183631; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02800503894183631; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02800503894183631; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.02800503894183631; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03107866187782014; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03107866187782014; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03107866187782014; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03107866187782014; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03107866187782014; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03448962260405758; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03448962260405758; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03448962260405758; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03448962260405758; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03448962260405758; total time=   0.0s\n",
      "[CV] END .........................alpha=0.038274944785163134; total time=   0.0s\n",
      "[CV] END .........................alpha=0.038274944785163134; total time=   0.0s\n",
      "[CV] END .........................alpha=0.038274944785163134; total time=   0.0s\n",
      "[CV] END .........................alpha=0.038274944785163134; total time=   0.0s\n",
      "[CV] END .........................alpha=0.038274944785163134; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.04247571552536898; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.04247571552536898; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.04247571552536898; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.04247571552536898; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.04247571552536898; total time=   0.0s\n",
      "[CV] END .........................alpha=0.047137531341167244; total time=   0.0s\n",
      "[CV] END .........................alpha=0.047137531341167244; total time=   0.0s\n",
      "[CV] END .........................alpha=0.047137531341167244; total time=   0.0s\n",
      "[CV] END .........................alpha=0.047137531341167244; total time=   0.0s\n",
      "[CV] END .........................alpha=0.047137531341167244; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05231099308056263; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05231099308056263; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05231099308056263; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05231099308056263; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05231099308056263; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05805225516094899; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05805225516094899; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05805225516094899; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05805225516094899; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.05805225516094899; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06442363508721373; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06442363508721373; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06442363508721373; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06442363508721373; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06442363508721373; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07149428986597581; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07149428986597581; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07149428986597581; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07149428986597581; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07149428986597581; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07934096665797492; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07934096665797492; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07934096665797492; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07934096665797492; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.07934096665797492; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.08804883581643465; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.08804883581643465; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.08804883581643465; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.08804883581643465; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.08804883581643465; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.09771241535346502; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.09771241535346502; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.09771241535346502; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.09771241535346502; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.09771241535346502; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1084365968689611; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1084365968689611; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1084365968689611; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1084365968689611; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1084365968689611; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.12033778407775893; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.12033778407775893; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.12033778407775893; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.12033778407775893; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.12033778407775893; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.13354515629298988; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.13354515629298988; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.13354515629298988; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.13354515629298988; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.13354515629298988; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14820207057988585; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14820207057988585; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14820207057988585; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14820207057988585; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14820207057988585; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.16446761779946645; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.16446761779946645; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.16446761779946645; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.16446761779946645; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.16446761779946645; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.18251834943190443; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.18251834943190443; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.18251834943190443; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.18251834943190443; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.18251834943190443; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.20255019392306664; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.20255019392306664; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.20255019392306664; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.20255019392306664; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.20255019392306664; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.22478058335487253; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.22478058335487253; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.22478058335487253; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.22478058335487253; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.22478058335487253; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.24945081352303167; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.24945081352303167; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.24945081352303167; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.24945081352303167; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.24945081352303167; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.27682866303920667; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.27682866303920667; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.27682866303920667; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.27682866303920667; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.27682866303920667; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3072112998861759; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3072112998861759; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3072112998861759; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3072112998861759; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3072112998861759; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.34092850697468147; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.34092850697468147; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.34092850697468147; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.34092850697468147; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.34092850697468147; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3783462617131929; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3783462617131929; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3783462617131929; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3783462617131929; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.3783462617131929; total time=   0.0s\n",
      "[CV] END ............................alpha=0.419870708444391; total time=   0.0s\n",
      "[CV] END ............................alpha=0.419870708444391; total time=   0.0s\n",
      "[CV] END ............................alpha=0.419870708444391; total time=   0.0s\n",
      "[CV] END ............................alpha=0.419870708444391; total time=   0.0s\n",
      "[CV] END ............................alpha=0.419870708444391; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.4659525668664682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.4659525668664682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.4659525668664682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.4659525668664682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.4659525668664682; total time=   0.0s\n",
      "[CV] END ............................alpha=0.517092024289676; total time=   0.0s\n",
      "[CV] END ............................alpha=0.517092024289676; total time=   0.0s\n",
      "[CV] END ............................alpha=0.517092024289676; total time=   0.0s\n",
      "[CV] END ............................alpha=0.517092024289676; total time=   0.0s\n",
      "[CV] END ............................alpha=0.517092024289676; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.5738441648302398; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.5738441648302398; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.5738441648302398; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.5738441648302398; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.5738441648302398; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.6368249944718586; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.6368249944718586; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.6368249944718586; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.6368249944718586; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.6368249944718586; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7067181273927491; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7067181273927491; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7067181273927491; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7067181273927491; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7067181273927491; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7842822061337682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7842822061337682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7842822061337682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7842822061337682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.7842822061337682; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.8703591361485166; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.8703591361485166; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.8703591361485166; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.8703591361485166; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.8703591361485166; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.9658832241158708; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.9658832241158708; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.9658832241158708; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.9658832241158708; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.9658832241158708; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.0718913192051276; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.0718913192051276; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.0718913192051276; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.0718913192051276; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.0718913192051276; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.1895340673703196; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.1895340673703196; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.1895340673703196; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.1895340673703196; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.1895340673703196; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.3200884008314182; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.3200884008314182; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.3200884008314182; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.3200884008314182; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.3200884008314182; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.4649713983072863; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.4649713983072863; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.4649713983072863; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.4649713983072863; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.4649713983072863; total time=   0.0s\n",
      "[CV] END ............................alpha=1.625755666443795; total time=   0.0s\n",
      "[CV] END ............................alpha=1.625755666443795; total time=   0.0s\n",
      "[CV] END ............................alpha=1.625755666443795; total time=   0.0s\n",
      "[CV] END ............................alpha=1.625755666443795; total time=   0.0s\n",
      "[CV] END ............................alpha=1.625755666443795; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.8041864093920719; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.8041864093920719; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.8041864093920719; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.8041864093920719; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.8041864093920719; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.0022003718155843; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.0022003718155843; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.0022003718155843; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.0022003718155843; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.0022003718155843; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.2219468609395236; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.2219468609395236; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.2219468609395236; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.2219468609395236; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.2219468609395236; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.4658110758226037; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.4658110758226037; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.4658110758226037; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.4658110758226037; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.4658110758226037; total time=   0.0s\n",
      "[CV] END ............................alpha=2.736439997074672; total time=   0.0s\n",
      "[CV] END ............................alpha=2.736439997074672; total time=   0.0s\n",
      "[CV] END ............................alpha=2.736439997074672; total time=   0.0s\n",
      "[CV] END ............................alpha=2.736439997074672; total time=   0.0s\n",
      "[CV] END ............................alpha=2.736439997074672; total time=   0.0s\n",
      "[CV] END ...........................alpha=3.0367711180354604; total time=   0.0s\n",
      "[CV] END ...........................alpha=3.0367711180354604; total time=   0.0s\n",
      "[CV] END ...........................alpha=3.0367711180354604; total time=   0.0s\n",
      "[CV] END ...........................alpha=3.0367711180354604; total time=   0.0s\n",
      "[CV] END ...........................alpha=3.0367711180354604; total time=   0.0s\n",
      "[CV] END ............................alpha=3.370064329271928; total time=   0.0s\n",
      "[CV] END ............................alpha=3.370064329271928; total time=   0.0s\n",
      "[CV] END ............................alpha=3.370064329271928; total time=   0.0s\n",
      "[CV] END ............................alpha=3.370064329271928; total time=   0.0s\n",
      "[CV] END ............................alpha=3.370064329271928; total time=   0.0s\n",
      "[CV] END ............................alpha=3.739937302478798; total time=   0.0s\n",
      "[CV] END ............................alpha=3.739937302478798; total time=   0.0s\n",
      "[CV] END ............................alpha=3.739937302478798; total time=   0.0s\n",
      "[CV] END ............................alpha=3.739937302478798; total time=   0.0s\n",
      "[CV] END ............................alpha=3.739937302478798; total time=   0.0s\n",
      "[CV] END ............................alpha=4.150404757850477; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=4.150404757850477; total time=   0.0s\n",
      "[CV] END ............................alpha=4.150404757850477; total time=   0.0s\n",
      "[CV] END ............................alpha=4.150404757850477; total time=   0.0s\n",
      "[CV] END ............................alpha=4.150404757850477; total time=   0.0s\n",
      "[CV] END ............................alpha=4.605922041145108; total time=   0.0s\n",
      "[CV] END ............................alpha=4.605922041145108; total time=   0.0s\n",
      "[CV] END ............................alpha=4.605922041145108; total time=   0.0s\n",
      "[CV] END ............................alpha=4.605922041145108; total time=   0.0s\n",
      "[CV] END ............................alpha=4.605922041145108; total time=   0.0s\n",
      "[CV] END ...........................alpha=5.1114334834401705; total time=   0.0s\n",
      "[CV] END ...........................alpha=5.1114334834401705; total time=   0.0s\n",
      "[CV] END ...........................alpha=5.1114334834401705; total time=   0.0s\n",
      "[CV] END ...........................alpha=5.1114334834401705; total time=   0.0s\n",
      "[CV] END ...........................alpha=5.1114334834401705; total time=   0.0s\n",
      "[CV] END ............................alpha=5.672426068491977; total time=   0.0s\n",
      "[CV] END ............................alpha=5.672426068491977; total time=   0.0s\n",
      "[CV] END ............................alpha=5.672426068491977; total time=   0.0s\n",
      "[CV] END ............................alpha=5.672426068491977; total time=   0.0s\n",
      "[CV] END ............................alpha=5.672426068491977; total time=   0.0s\n",
      "[CV] END ............................alpha=6.294988990221888; total time=   0.0s\n",
      "[CV] END ............................alpha=6.294988990221888; total time=   0.0s\n",
      "[CV] END ............................alpha=6.294988990221888; total time=   0.0s\n",
      "[CV] END ............................alpha=6.294988990221888; total time=   0.0s\n",
      "[CV] END ............................alpha=6.294988990221888; total time=   0.0s\n",
      "[CV] END ............................alpha=6.985879746785249; total time=   0.0s\n",
      "[CV] END ............................alpha=6.985879746785249; total time=   0.0s\n",
      "[CV] END ............................alpha=6.985879746785249; total time=   0.0s\n",
      "[CV] END ............................alpha=6.985879746785249; total time=   0.0s\n",
      "[CV] END ............................alpha=6.985879746785249; total time=   0.0s\n",
      "[CV] END ............................alpha=7.752597488629465; total time=   0.0s\n",
      "[CV] END ............................alpha=7.752597488629465; total time=   0.0s\n",
      "[CV] END ............................alpha=7.752597488629465; total time=   0.0s\n",
      "[CV] END ............................alpha=7.752597488629465; total time=   0.0s\n",
      "[CV] END ............................alpha=7.752597488629465; total time=   0.0s\n",
      "[CV] END .............................alpha=8.60346441668451; total time=   0.0s\n",
      "[CV] END .............................alpha=8.60346441668451; total time=   0.0s\n",
      "[CV] END .............................alpha=8.60346441668451; total time=   0.0s\n",
      "[CV] END .............................alpha=8.60346441668451; total time=   0.0s\n",
      "[CV] END .............................alpha=8.60346441668451; total time=   0.0s\n",
      "[CV] END ............................alpha=9.547716114208066; total time=   0.0s\n",
      "[CV] END ............................alpha=9.547716114208066; total time=   0.0s\n",
      "[CV] END ............................alpha=9.547716114208066; total time=   0.0s\n",
      "[CV] END ............................alpha=9.547716114208066; total time=   0.0s\n",
      "[CV] END ............................alpha=9.547716114208066; total time=   0.0s\n",
      "[CV] END ............................alpha=10.59560179277617; total time=   0.0s\n",
      "[CV] END ............................alpha=10.59560179277617; total time=   0.0s\n",
      "[CV] END ............................alpha=10.59560179277617; total time=   0.0s\n",
      "[CV] END ............................alpha=10.59560179277617; total time=   0.0s\n",
      "[CV] END ............................alpha=10.59560179277617; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.758495540521581; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.758495540521581; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.758495540521581; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.758495540521581; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.758495540521581; total time=   0.0s\n",
      "[CV] END ...........................alpha=13.049019780144016; total time=   0.0s\n",
      "[CV] END ...........................alpha=13.049019780144016; total time=   0.0s\n",
      "[CV] END ...........................alpha=13.049019780144016; total time=   0.0s\n",
      "[CV] END ...........................alpha=13.049019780144016; total time=   0.0s\n",
      "[CV] END ...........................alpha=13.049019780144016; total time=   0.0s\n",
      "[CV] END ...........................alpha=14.481182276745331; total time=   0.0s\n",
      "[CV] END ...........................alpha=14.481182276745331; total time=   0.0s\n",
      "[CV] END ...........................alpha=14.481182276745331; total time=   0.0s\n",
      "[CV] END ...........................alpha=14.481182276745331; total time=   0.0s\n",
      "[CV] END ...........................alpha=14.481182276745331; total time=   0.0s\n",
      "[CV] END ...........................alpha=16.070528182616385; total time=   0.0s\n",
      "[CV] END ...........................alpha=16.070528182616385; total time=   0.0s\n",
      "[CV] END ...........................alpha=16.070528182616385; total time=   0.0s\n",
      "[CV] END ...........................alpha=16.070528182616385; total time=   0.0s\n",
      "[CV] END ...........................alpha=16.070528182616385; total time=   0.0s\n",
      "[CV] END ...........................alpha=17.834308769319094; total time=   0.0s\n",
      "[CV] END ...........................alpha=17.834308769319094; total time=   0.0s\n",
      "[CV] END ...........................alpha=17.834308769319094; total time=   0.0s\n",
      "[CV] END ...........................alpha=17.834308769319094; total time=   0.0s\n",
      "[CV] END ...........................alpha=17.834308769319094; total time=   0.0s\n",
      "[CV] END ...........................alpha=19.791668678535572; total time=   0.0s\n",
      "[CV] END ...........................alpha=19.791668678535572; total time=   0.0s\n",
      "[CV] END ...........................alpha=19.791668678535572; total time=   0.0s\n",
      "[CV] END ...........................alpha=19.791668678535572; total time=   0.0s\n",
      "[CV] END ...........................alpha=19.791668678535572; total time=   0.0s\n",
      "[CV] END ............................alpha=21.96385372416547; total time=   0.0s\n",
      "[CV] END ............................alpha=21.96385372416547; total time=   0.0s\n",
      "[CV] END ............................alpha=21.96385372416547; total time=   0.0s\n",
      "[CV] END ............................alpha=21.96385372416547; total time=   0.0s\n",
      "[CV] END ............................alpha=21.96385372416547; total time=   0.0s\n",
      "[CV] END ............................alpha=24.37444150122222; total time=   0.0s\n",
      "[CV] END ............................alpha=24.37444150122222; total time=   0.0s\n",
      "[CV] END ............................alpha=24.37444150122222; total time=   0.0s\n",
      "[CV] END ............................alpha=24.37444150122222; total time=   0.0s\n",
      "[CV] END ............................alpha=24.37444150122222; total time=   0.0s\n",
      "[CV] END ............................alpha=27.04959730463137; total time=   0.0s\n",
      "[CV] END ............................alpha=27.04959730463137; total time=   0.0s\n",
      "[CV] END ............................alpha=27.04959730463137; total time=   0.0s\n",
      "[CV] END ............................alpha=27.04959730463137; total time=   0.0s\n",
      "[CV] END ............................alpha=27.04959730463137; total time=   0.0s\n",
      "[CV] END ............................alpha=30.01835813575592; total time=   0.0s\n",
      "[CV] END ............................alpha=30.01835813575592; total time=   0.0s\n",
      "[CV] END ............................alpha=30.01835813575592; total time=   0.0s\n",
      "[CV] END ............................alpha=30.01835813575592; total time=   0.0s\n",
      "[CV] END ............................alpha=30.01835813575592; total time=   0.0s\n",
      "[CV] END ............................alpha=33.31294787934677; total time=   0.0s\n",
      "[CV] END ............................alpha=33.31294787934677; total time=   0.0s\n",
      "[CV] END ............................alpha=33.31294787934677; total time=   0.0s\n",
      "[CV] END ............................alpha=33.31294787934677; total time=   0.0s\n",
      "[CV] END ............................alpha=33.31294787934677; total time=   0.0s\n",
      "[CV] END ............................alpha=36.96912707195032; total time=   0.0s\n",
      "[CV] END ............................alpha=36.96912707195032; total time=   0.0s\n",
      "[CV] END ............................alpha=36.96912707195032; total time=   0.0s\n",
      "[CV] END ............................alpha=36.96912707195032; total time=   0.0s\n",
      "[CV] END ............................alpha=36.96912707195032; total time=   0.0s\n",
      "[CV] END .............................alpha=41.0265810582719; total time=   0.0s\n",
      "[CV] END .............................alpha=41.0265810582719; total time=   0.0s\n",
      "[CV] END .............................alpha=41.0265810582719; total time=   0.0s\n",
      "[CV] END .............................alpha=41.0265810582719; total time=   0.0s\n",
      "[CV] END .............................alpha=41.0265810582719; total time=   0.0s\n",
      "[CV] END ............................alpha=45.52935074866948; total time=   0.0s\n",
      "[CV] END ............................alpha=45.52935074866948; total time=   0.0s\n",
      "[CV] END ............................alpha=45.52935074866948; total time=   0.0s\n",
      "[CV] END ............................alpha=45.52935074866948; total time=   0.0s\n",
      "[CV] END ............................alpha=45.52935074866948; total time=   0.0s\n",
      "[CV] END ...........................alpha=50.526310653356795; total time=   0.0s\n",
      "[CV] END ...........................alpha=50.526310653356795; total time=   0.0s\n",
      "[CV] END ...........................alpha=50.526310653356795; total time=   0.0s\n",
      "[CV] END ...........................alpha=50.526310653356795; total time=   0.0s\n",
      "[CV] END ...........................alpha=50.526310653356795; total time=   0.0s\n",
      "[CV] END ............................alpha=56.07169938205458; total time=   0.0s\n",
      "[CV] END ............................alpha=56.07169938205458; total time=   0.0s\n",
      "[CV] END ............................alpha=56.07169938205458; total time=   0.0s\n",
      "[CV] END ............................alpha=56.07169938205458; total time=   0.0s\n",
      "[CV] END ............................alpha=56.07169938205458; total time=   0.0s\n",
      "[CV] END ............................alpha=62.22570836730231; total time=   0.0s\n",
      "[CV] END ............................alpha=62.22570836730231; total time=   0.0s\n",
      "[CV] END ............................alpha=62.22570836730231; total time=   0.0s\n",
      "[CV] END ............................alpha=62.22570836730231; total time=   0.0s\n",
      "[CV] END ............................alpha=62.22570836730231; total time=   0.0s\n",
      "[CV] END .............................alpha=69.0551352016233; total time=   0.0s\n",
      "[CV] END .............................alpha=69.0551352016233; total time=   0.0s\n",
      "[CV] END .............................alpha=69.0551352016233; total time=   0.0s\n",
      "[CV] END .............................alpha=69.0551352016233; total time=   0.0s\n",
      "[CV] END .............................alpha=69.0551352016233; total time=   0.0s\n",
      "[CV] END ............................alpha=76.63410868007462; total time=   0.0s\n",
      "[CV] END ............................alpha=76.63410868007462; total time=   0.0s\n",
      "[CV] END ............................alpha=76.63410868007462; total time=   0.0s\n",
      "[CV] END ............................alpha=76.63410868007462; total time=   0.0s\n",
      "[CV] END ............................alpha=76.63410868007462; total time=   0.0s\n",
      "[CV] END ............................alpha=85.04489341802686; total time=   0.0s\n",
      "[CV] END ............................alpha=85.04489341802686; total time=   0.0s\n",
      "[CV] END ............................alpha=85.04489341802686; total time=   0.0s\n",
      "[CV] END ............................alpha=85.04489341802686; total time=   0.0s\n",
      "[CV] END ............................alpha=85.04489341802686; total time=   0.0s\n",
      "[CV] END ............................alpha=94.37878277775391; total time=   0.0s\n",
      "[CV] END ............................alpha=94.37878277775391; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=94.37878277775391; total time=   0.0s\n",
      "[CV] END ............................alpha=94.37878277775391; total time=   0.0s\n",
      "[CV] END ............................alpha=94.37878277775391; total time=   0.0s\n",
      "[CV] END ...........................alpha=104.73708979594508; total time=   0.0s\n",
      "[CV] END ...........................alpha=104.73708979594508; total time=   0.0s\n",
      "[CV] END ...........................alpha=104.73708979594508; total time=   0.0s\n",
      "[CV] END ...........................alpha=104.73708979594508; total time=   0.0s\n",
      "[CV] END ...........................alpha=104.73708979594508; total time=   0.0s\n",
      "[CV] END ...........................alpha=116.23224686798542; total time=   0.0s\n",
      "[CV] END ...........................alpha=116.23224686798542; total time=   0.0s\n",
      "[CV] END ...........................alpha=116.23224686798542; total time=   0.0s\n",
      "[CV] END ...........................alpha=116.23224686798542; total time=   0.0s\n",
      "[CV] END ...........................alpha=116.23224686798542; total time=   0.0s\n",
      "[CV] END ............................alpha=128.9890261253308; total time=   0.0s\n",
      "[CV] END ............................alpha=128.9890261253308; total time=   0.0s\n",
      "[CV] END ............................alpha=128.9890261253308; total time=   0.0s\n",
      "[CV] END ............................alpha=128.9890261253308; total time=   0.0s\n",
      "[CV] END ............................alpha=128.9890261253308; total time=   0.0s\n",
      "[CV] END ...........................alpha=143.14589375234786; total time=   0.0s\n",
      "[CV] END ...........................alpha=143.14589375234786; total time=   0.0s\n",
      "[CV] END ...........................alpha=143.14589375234786; total time=   0.0s\n",
      "[CV] END ...........................alpha=143.14589375234786; total time=   0.0s\n",
      "[CV] END ...........................alpha=143.14589375234786; total time=   0.0s\n",
      "[CV] END ...........................alpha=158.85651294280527; total time=   0.0s\n",
      "[CV] END ...........................alpha=158.85651294280527; total time=   0.0s\n",
      "[CV] END ...........................alpha=158.85651294280527; total time=   0.0s\n",
      "[CV] END ...........................alpha=158.85651294280527; total time=   0.0s\n",
      "[CV] END ...........................alpha=158.85651294280527; total time=   0.0s\n",
      "[CV] END ............................alpha=176.2914118095948; total time=   0.0s\n",
      "[CV] END ............................alpha=176.2914118095948; total time=   0.0s\n",
      "[CV] END ............................alpha=176.2914118095948; total time=   0.0s\n",
      "[CV] END ............................alpha=176.2914118095948; total time=   0.0s\n",
      "[CV] END ............................alpha=176.2914118095948; total time=   0.0s\n",
      "[CV] END ...........................alpha=195.63983435170647; total time=   0.0s\n",
      "[CV] END ...........................alpha=195.63983435170647; total time=   0.0s\n",
      "[CV] END ...........................alpha=195.63983435170647; total time=   0.0s\n",
      "[CV] END ...........................alpha=195.63983435170647; total time=   0.0s\n",
      "[CV] END ...........................alpha=195.63983435170647; total time=   0.0s\n",
      "[CV] END ...........................alpha=217.11179456945052; total time=   0.0s\n",
      "[CV] END ...........................alpha=217.11179456945052; total time=   0.0s\n",
      "[CV] END ...........................alpha=217.11179456945052; total time=   0.0s\n",
      "[CV] END ...........................alpha=217.11179456945052; total time=   0.0s\n",
      "[CV] END ...........................alpha=217.11179456945052; total time=   0.0s\n",
      "[CV] END ............................alpha=240.9403560239527; total time=   0.0s\n",
      "[CV] END ............................alpha=240.9403560239527; total time=   0.0s\n",
      "[CV] END ............................alpha=240.9403560239527; total time=   0.0s\n",
      "[CV] END ............................alpha=240.9403560239527; total time=   0.0s\n",
      "[CV] END ............................alpha=240.9403560239527; total time=   0.0s\n",
      "[CV] END ...........................alpha=267.38416158399497; total time=   0.0s\n",
      "[CV] END ...........................alpha=267.38416158399497; total time=   0.0s\n",
      "[CV] END ...........................alpha=267.38416158399497; total time=   0.0s\n",
      "[CV] END ...........................alpha=267.38416158399497; total time=   0.0s\n",
      "[CV] END ...........................alpha=267.38416158399497; total time=   0.0s\n",
      "[CV] END ...........................alpha=296.73024081888724; total time=   0.0s\n",
      "[CV] END ...........................alpha=296.73024081888724; total time=   0.0s\n",
      "[CV] END ...........................alpha=296.73024081888724; total time=   0.0s\n",
      "[CV] END ...........................alpha=296.73024081888724; total time=   0.0s\n",
      "[CV] END ...........................alpha=296.73024081888724; total time=   0.0s\n",
      "[CV] END ............................alpha=329.2971255097155; total time=   0.0s\n",
      "[CV] END ............................alpha=329.2971255097155; total time=   0.0s\n",
      "[CV] END ............................alpha=329.2971255097155; total time=   0.0s\n",
      "[CV] END ............................alpha=329.2971255097155; total time=   0.0s\n",
      "[CV] END ............................alpha=329.2971255097155; total time=   0.0s\n",
      "[CV] END ...........................alpha=365.43830709572546; total time=   0.0s\n",
      "[CV] END ...........................alpha=365.43830709572546; total time=   0.0s\n",
      "[CV] END ...........................alpha=365.43830709572546; total time=   0.0s\n",
      "[CV] END ...........................alpha=365.43830709572546; total time=   0.0s\n",
      "[CV] END ...........................alpha=365.43830709572546; total time=   0.0s\n",
      "[CV] END ...........................alpha=405.54607358408276; total time=   0.0s\n",
      "[CV] END ...........................alpha=405.54607358408276; total time=   0.0s\n",
      "[CV] END ...........................alpha=405.54607358408276; total time=   0.0s\n",
      "[CV] END ...........................alpha=405.54607358408276; total time=   0.0s\n",
      "[CV] END ...........................alpha=405.54607358408276; total time=   0.0s\n",
      "[CV] END ...........................alpha=450.05576757004974; total time=   0.0s\n",
      "[CV] END ...........................alpha=450.05576757004974; total time=   0.0s\n",
      "[CV] END ...........................alpha=450.05576757004974; total time=   0.0s\n",
      "[CV] END ...........................alpha=450.05576757004974; total time=   0.0s\n",
      "[CV] END ...........................alpha=450.05576757004974; total time=   0.0s\n",
      "[CV] END .............................alpha=499.450511585514; total time=   0.0s\n",
      "[CV] END .............................alpha=499.450511585514; total time=   0.0s\n",
      "[CV] END .............................alpha=499.450511585514; total time=   0.0s\n",
      "[CV] END .............................alpha=499.450511585514; total time=   0.0s\n",
      "[CV] END .............................alpha=499.450511585514; total time=   0.0s\n",
      "[CV] END ............................alpha=554.2664520663108; total time=   0.0s\n",
      "[CV] END ............................alpha=554.2664520663108; total time=   0.0s\n",
      "[CV] END ............................alpha=554.2664520663108; total time=   0.0s\n",
      "[CV] END ............................alpha=554.2664520663108; total time=   0.0s\n",
      "[CV] END ............................alpha=554.2664520663108; total time=   0.0s\n",
      "[CV] END ............................alpha=615.0985788580505; total time=   0.0s\n",
      "[CV] END ............................alpha=615.0985788580505; total time=   0.0s\n",
      "[CV] END ............................alpha=615.0985788580505; total time=   0.0s\n",
      "[CV] END ............................alpha=615.0985788580505; total time=   0.0s\n",
      "[CV] END ............................alpha=615.0985788580505; total time=   0.0s\n",
      "[CV] END ............................alpha=682.6071834272393; total time=   0.0s\n",
      "[CV] END ............................alpha=682.6071834272393; total time=   0.0s\n",
      "[CV] END ............................alpha=682.6071834272393; total time=   0.0s\n",
      "[CV] END ............................alpha=682.6071834272393; total time=   0.0s\n",
      "[CV] END ............................alpha=682.6071834272393; total time=   0.0s\n",
      "[CV] END .............................alpha=757.525025877192; total time=   0.0s\n",
      "[CV] END .............................alpha=757.525025877192; total time=   0.0s\n",
      "[CV] END .............................alpha=757.525025877192; total time=   0.0s\n",
      "[CV] END .............................alpha=757.525025877192; total time=   0.0s\n",
      "[CV] END .............................alpha=757.525025877192; total time=   0.0s\n",
      "[CV] END ............................alpha=840.6652885618333; total time=   0.0s\n",
      "[CV] END ............................alpha=840.6652885618333; total time=   0.0s\n",
      "[CV] END ............................alpha=840.6652885618333; total time=   0.0s\n",
      "[CV] END ............................alpha=840.6652885618333; total time=   0.0s\n",
      "[CV] END ............................alpha=840.6652885618333; total time=   0.0s\n",
      "[CV] END ............................alpha=932.9304026284696; total time=   0.0s\n",
      "[CV] END ............................alpha=932.9304026284696; total time=   0.0s\n",
      "[CV] END ............................alpha=932.9304026284696; total time=   0.0s\n",
      "[CV] END ............................alpha=932.9304026284696; total time=   0.0s\n",
      "[CV] END ............................alpha=932.9304026284696; total time=   0.0s\n",
      "[CV] END ...........................alpha=1035.3218432956637; total time=   0.0s\n",
      "[CV] END ...........................alpha=1035.3218432956637; total time=   0.0s\n",
      "[CV] END ...........................alpha=1035.3218432956637; total time=   0.0s\n",
      "[CV] END ...........................alpha=1035.3218432956637; total time=   0.0s\n",
      "[CV] END ...........................alpha=1035.3218432956637; total time=   0.0s\n",
      "[CV] END ...........................alpha=1148.9510001873086; total time=   0.0s\n",
      "[CV] END ...........................alpha=1148.9510001873086; total time=   0.0s\n",
      "[CV] END ...........................alpha=1148.9510001873086; total time=   0.0s\n",
      "[CV] END ...........................alpha=1148.9510001873086; total time=   0.0s\n",
      "[CV] END ...........................alpha=1148.9510001873086; total time=   0.0s\n",
      "[CV] END ............................alpha=1275.051240713013; total time=   0.0s\n",
      "[CV] END ............................alpha=1275.051240713013; total time=   0.0s\n",
      "[CV] END ............................alpha=1275.051240713013; total time=   0.0s\n",
      "[CV] END ............................alpha=1275.051240713013; total time=   0.0s\n",
      "[CV] END ............................alpha=1275.051240713013; total time=   0.0s\n",
      "[CV] END ............................alpha=1414.991297434576; total time=   0.0s\n",
      "[CV] END ............................alpha=1414.991297434576; total time=   0.0s\n",
      "[CV] END ............................alpha=1414.991297434576; total time=   0.0s\n",
      "[CV] END ............................alpha=1414.991297434576; total time=   0.0s\n",
      "[CV] END ............................alpha=1414.991297434576; total time=   0.0s\n",
      "[CV] END ...........................alpha=1570.2901247293776; total time=   0.0s\n",
      "[CV] END ...........................alpha=1570.2901247293776; total time=   0.0s\n",
      "[CV] END ...........................alpha=1570.2901247293776; total time=   0.0s\n",
      "[CV] END ...........................alpha=1570.2901247293776; total time=   0.0s\n",
      "[CV] END ...........................alpha=1570.2901247293776; total time=   0.0s\n",
      "[CV] END ...........................alpha=1742.6333860096508; total time=   0.0s\n",
      "[CV] END ...........................alpha=1742.6333860096508; total time=   0.0s\n",
      "[CV] END ...........................alpha=1742.6333860096508; total time=   0.0s\n",
      "[CV] END ...........................alpha=1742.6333860096508; total time=   0.0s\n",
      "[CV] END ...........................alpha=1742.6333860096508; total time=   0.0s\n",
      "[CV] END ............................alpha=1933.891750455232; total time=   0.0s\n",
      "[CV] END ............................alpha=1933.891750455232; total time=   0.0s\n",
      "[CV] END ............................alpha=1933.891750455232; total time=   0.0s\n",
      "[CV] END ............................alpha=1933.891750455232; total time=   0.0s\n",
      "[CV] END ............................alpha=1933.891750455232; total time=   0.0s\n",
      "[CV] END ............................alpha=2146.141197858406; total time=   0.0s\n",
      "[CV] END ............................alpha=2146.141197858406; total time=   0.0s\n",
      "[CV] END ............................alpha=2146.141197858406; total time=   0.0s\n",
      "[CV] END ............................alpha=2146.141197858406; total time=   0.0s\n",
      "[CV] END ............................alpha=2146.141197858406; total time=   0.0s\n",
      "[CV] END ...........................alpha=2381.6855519761607; total time=   0.0s\n",
      "[CV] END ...........................alpha=2381.6855519761607; total time=   0.0s\n",
      "[CV] END ...........................alpha=2381.6855519761607; total time=   0.0s\n",
      "[CV] END ...........................alpha=2381.6855519761607; total time=   0.0s\n",
      "[CV] END ...........................alpha=2381.6855519761607; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=2643.0814869741084; total time=   0.0s\n",
      "[CV] END ...........................alpha=2643.0814869741084; total time=   0.0s\n",
      "[CV] END ...........................alpha=2643.0814869741084; total time=   0.0s\n",
      "[CV] END ...........................alpha=2643.0814869741084; total time=   0.0s\n",
      "[CV] END ...........................alpha=2643.0814869741084; total time=   0.0s\n",
      "[CV] END ...........................alpha=2933.1662783900483; total time=   0.0s\n",
      "[CV] END ...........................alpha=2933.1662783900483; total time=   0.0s\n",
      "[CV] END ...........................alpha=2933.1662783900483; total time=   0.0s\n",
      "[CV] END ...........................alpha=2933.1662783900483; total time=   0.0s\n",
      "[CV] END ...........................alpha=2933.1662783900483; total time=   0.0s\n",
      "[CV] END ...........................alpha=3255.0885998350564; total time=   0.0s\n",
      "[CV] END ...........................alpha=3255.0885998350564; total time=   0.0s\n",
      "[CV] END ...........................alpha=3255.0885998350564; total time=   0.0s\n",
      "[CV] END ...........................alpha=3255.0885998350564; total time=   0.0s\n",
      "[CV] END ...........................alpha=3255.0885998350564; total time=   0.0s\n",
      "[CV] END ...........................alpha=3612.3426997094302; total time=   0.0s\n",
      "[CV] END ...........................alpha=3612.3426997094302; total time=   0.0s\n",
      "[CV] END ...........................alpha=3612.3426997094302; total time=   0.0s\n",
      "[CV] END ...........................alpha=3612.3426997094302; total time=   0.0s\n",
      "[CV] END ...........................alpha=3612.3426997094302; total time=   0.0s\n",
      "[CV] END ...........................alpha=4008.8063288984645; total time=   0.0s\n",
      "[CV] END ...........................alpha=4008.8063288984645; total time=   0.0s\n",
      "[CV] END ...........................alpha=4008.8063288984645; total time=   0.0s\n",
      "[CV] END ...........................alpha=4008.8063288984645; total time=   0.0s\n",
      "[CV] END ...........................alpha=4008.8063288984645; total time=   0.0s\n",
      "[CV] END ............................alpha=4448.782831127585; total time=   0.0s\n",
      "[CV] END ............................alpha=4448.782831127585; total time=   0.0s\n",
      "[CV] END ............................alpha=4448.782831127585; total time=   0.0s\n",
      "[CV] END ............................alpha=4448.782831127585; total time=   0.0s\n",
      "[CV] END ............................alpha=4448.782831127585; total time=   0.0s\n",
      "[CV] END ............................alpha=4937.047852839004; total time=   0.0s\n",
      "[CV] END ............................alpha=4937.047852839004; total time=   0.0s\n",
      "[CV] END ............................alpha=4937.047852839004; total time=   0.0s\n",
      "[CV] END ............................alpha=4937.047852839004; total time=   0.0s\n",
      "[CV] END ............................alpha=4937.047852839004; total time=   0.0s\n",
      "[CV] END ............................alpha=5478.901179593945; total time=   0.0s\n",
      "[CV] END ............................alpha=5478.901179593945; total time=   0.0s\n",
      "[CV] END ............................alpha=5478.901179593945; total time=   0.0s\n",
      "[CV] END ............................alpha=5478.901179593945; total time=   0.0s\n",
      "[CV] END ............................alpha=5478.901179593945; total time=   0.0s\n",
      "[CV] END ............................alpha=6080.224261649427; total time=   0.0s\n",
      "[CV] END ............................alpha=6080.224261649427; total time=   0.0s\n",
      "[CV] END ............................alpha=6080.224261649427; total time=   0.0s\n",
      "[CV] END ............................alpha=6080.224261649427; total time=   0.0s\n",
      "[CV] END ............................alpha=6080.224261649427; total time=   0.0s\n",
      "[CV] END ..............................alpha=6747.5440531107; total time=   0.0s\n",
      "[CV] END ..............................alpha=6747.5440531107; total time=   0.0s\n",
      "[CV] END ..............................alpha=6747.5440531107; total time=   0.0s\n",
      "[CV] END ..............................alpha=6747.5440531107; total time=   0.0s\n",
      "[CV] END ..............................alpha=6747.5440531107; total time=   0.0s\n",
      "[CV] END .............................alpha=7488.10385759003; total time=   0.0s\n",
      "[CV] END .............................alpha=7488.10385759003; total time=   0.0s\n",
      "[CV] END .............................alpha=7488.10385759003; total time=   0.0s\n",
      "[CV] END .............................alpha=7488.10385759003; total time=   0.0s\n",
      "[CV] END .............................alpha=7488.10385759003; total time=   0.0s\n",
      "[CV] END ............................alpha=8309.941949353404; total time=   0.0s\n",
      "[CV] END ............................alpha=8309.941949353404; total time=   0.0s\n",
      "[CV] END ............................alpha=8309.941949353404; total time=   0.0s\n",
      "[CV] END ............................alpha=8309.941949353404; total time=   0.0s\n",
      "[CV] END ............................alpha=8309.941949353404; total time=   0.0s\n",
      "[CV] END .............................alpha=9221.97882333434; total time=   0.0s\n",
      "[CV] END .............................alpha=9221.97882333434; total time=   0.0s\n",
      "[CV] END .............................alpha=9221.97882333434; total time=   0.0s\n",
      "[CV] END .............................alpha=9221.97882333434; total time=   0.0s\n",
      "[CV] END .............................alpha=9221.97882333434; total time=   0.0s\n",
      "[CV] END ...........................alpha=10234.114021054527; total time=   0.0s\n",
      "[CV] END ...........................alpha=10234.114021054527; total time=   0.0s\n",
      "[CV] END ...........................alpha=10234.114021054527; total time=   0.0s\n",
      "[CV] END ...........................alpha=10234.114021054527; total time=   0.0s\n",
      "[CV] END ...........................alpha=10234.114021054527; total time=   0.0s\n",
      "[CV] END ...........................alpha=11357.333583431051; total time=   0.0s\n",
      "[CV] END ...........................alpha=11357.333583431051; total time=   0.0s\n",
      "[CV] END ...........................alpha=11357.333583431051; total time=   0.0s\n",
      "[CV] END ...........................alpha=11357.333583431051; total time=   0.0s\n",
      "[CV] END ...........................alpha=11357.333583431051; total time=   0.0s\n",
      "[CV] END ...........................alpha=12603.829296797274; total time=   0.0s\n",
      "[CV] END ...........................alpha=12603.829296797274; total time=   0.0s\n",
      "[CV] END ...........................alpha=12603.829296797274; total time=   0.0s\n",
      "[CV] END ...........................alpha=12603.829296797274; total time=   0.0s\n",
      "[CV] END ...........................alpha=12603.829296797274; total time=   0.0s\n",
      "[CV] END ...........................alpha=13987.131026472387; total time=   0.0s\n",
      "[CV] END ...........................alpha=13987.131026472387; total time=   0.0s\n",
      "[CV] END ...........................alpha=13987.131026472387; total time=   0.0s\n",
      "[CV] END ...........................alpha=13987.131026472387; total time=   0.0s\n",
      "[CV] END ...........................alpha=13987.131026472387; total time=   0.0s\n",
      "[CV] END ............................alpha=15522.25357427048; total time=   0.0s\n",
      "[CV] END ............................alpha=15522.25357427048; total time=   0.0s\n",
      "[CV] END ............................alpha=15522.25357427048; total time=   0.0s\n",
      "[CV] END ............................alpha=15522.25357427048; total time=   0.0s\n",
      "[CV] END ............................alpha=15522.25357427048; total time=   0.0s\n",
      "[CV] END ...........................alpha=17225.859653987874; total time=   0.0s\n",
      "[CV] END ...........................alpha=17225.859653987874; total time=   0.0s\n",
      "[CV] END ...........................alpha=17225.859653987874; total time=   0.0s\n",
      "[CV] END ...........................alpha=17225.859653987874; total time=   0.0s\n",
      "[CV] END ...........................alpha=17225.859653987874; total time=   0.0s\n",
      "[CV] END ...........................alpha=19116.440753857038; total time=   0.0s\n",
      "[CV] END ...........................alpha=19116.440753857038; total time=   0.0s\n",
      "[CV] END ...........................alpha=19116.440753857038; total time=   0.0s\n",
      "[CV] END ...........................alpha=19116.440753857038; total time=   0.0s\n",
      "[CV] END ...........................alpha=19116.440753857038; total time=   0.0s\n",
      "[CV] END ............................alpha=21214.51784910632; total time=   0.0s\n",
      "[CV] END ............................alpha=21214.51784910632; total time=   0.0s\n",
      "[CV] END ............................alpha=21214.51784910632; total time=   0.0s\n",
      "[CV] END ............................alpha=21214.51784910632; total time=   0.0s\n",
      "[CV] END ............................alpha=21214.51784910632; total time=   0.0s\n",
      "[CV] END ...........................alpha=23542.864143224204; total time=   0.0s\n",
      "[CV] END ...........................alpha=23542.864143224204; total time=   0.0s\n",
      "[CV] END ...........................alpha=23542.864143224204; total time=   0.0s\n",
      "[CV] END ...........................alpha=23542.864143224204; total time=   0.0s\n",
      "[CV] END ...........................alpha=23542.864143224204; total time=   0.0s\n",
      "[CV] END ...........................alpha=26126.752255633317; total time=   0.0s\n",
      "[CV] END ...........................alpha=26126.752255633317; total time=   0.0s\n",
      "[CV] END ...........................alpha=26126.752255633317; total time=   0.0s\n",
      "[CV] END ...........................alpha=26126.752255633317; total time=   0.0s\n",
      "[CV] END ...........................alpha=26126.752255633317; total time=   0.0s\n",
      "[CV] END ............................alpha=28994.22853882881; total time=   0.0s\n",
      "[CV] END ............................alpha=28994.22853882881; total time=   0.0s\n",
      "[CV] END ............................alpha=28994.22853882881; total time=   0.0s\n",
      "[CV] END ............................alpha=28994.22853882881; total time=   0.0s\n",
      "[CV] END ............................alpha=28994.22853882881; total time=   0.0s\n",
      "[CV] END ...........................alpha=32176.417502507353; total time=   0.0s\n",
      "[CV] END ...........................alpha=32176.417502507353; total time=   0.0s\n",
      "[CV] END ...........................alpha=32176.417502507353; total time=   0.0s\n",
      "[CV] END ...........................alpha=32176.417502507353; total time=   0.0s\n",
      "[CV] END ...........................alpha=32176.417502507353; total time=   0.0s\n",
      "[CV] END ...........................alpha=35707.859649004626; total time=   0.0s\n",
      "[CV] END ...........................alpha=35707.859649004626; total time=   0.0s\n",
      "[CV] END ...........................alpha=35707.859649004626; total time=   0.0s\n",
      "[CV] END ...........................alpha=35707.859649004626; total time=   0.0s\n",
      "[CV] END ...........................alpha=35707.859649004626; total time=   0.0s\n",
      "[CV] END ............................alpha=39626.88638701478; total time=   0.0s\n",
      "[CV] END ............................alpha=39626.88638701478; total time=   0.0s\n",
      "[CV] END ............................alpha=39626.88638701478; total time=   0.0s\n",
      "[CV] END ............................alpha=39626.88638701478; total time=   0.0s\n",
      "[CV] END ............................alpha=39626.88638701478; total time=   0.0s\n",
      "[CV] END ...........................alpha=43976.036093027215; total time=   0.0s\n",
      "[CV] END ...........................alpha=43976.036093027215; total time=   0.0s\n",
      "[CV] END ...........................alpha=43976.036093027215; total time=   0.0s\n",
      "[CV] END ...........................alpha=43976.036093027215; total time=   0.0s\n",
      "[CV] END ...........................alpha=43976.036093027215; total time=   0.0s\n",
      "[CV] END ...........................alpha=48802.515836544335; total time=   0.0s\n",
      "[CV] END ...........................alpha=48802.515836544335; total time=   0.0s\n",
      "[CV] END ...........................alpha=48802.515836544335; total time=   0.0s\n",
      "[CV] END ...........................alpha=48802.515836544335; total time=   0.0s\n",
      "[CV] END ...........................alpha=48802.515836544335; total time=   0.0s\n",
      "[CV] END ............................alpha=54158.71378079476; total time=   0.0s\n",
      "[CV] END ............................alpha=54158.71378079476; total time=   0.0s\n",
      "[CV] END ............................alpha=54158.71378079476; total time=   0.0s\n",
      "[CV] END ............................alpha=54158.71378079476; total time=   0.0s\n",
      "[CV] END ............................alpha=54158.71378079476; total time=   0.0s\n",
      "[CV] END ............................alpha=60102.76782070388; total time=   0.0s\n",
      "[CV] END ............................alpha=60102.76782070388; total time=   0.0s\n",
      "[CV] END ............................alpha=60102.76782070388; total time=   0.0s\n",
      "[CV] END ............................alpha=60102.76782070388; total time=   0.0s\n",
      "[CV] END ............................alpha=60102.76782070388; total time=   0.0s\n",
      "[CV] END ............................alpha=66699.19663030129; total time=   0.0s\n",
      "[CV] END ............................alpha=66699.19663030129; total time=   0.0s\n",
      "[CV] END ............................alpha=66699.19663030129; total time=   0.0s\n",
      "[CV] END ............................alpha=66699.19663030129; total time=   0.0s\n",
      "[CV] END ............................alpha=66699.19663030129; total time=   0.0s\n",
      "[CV] END ............................alpha=74019.59996915652; total time=   0.0s\n",
      "[CV] END ............................alpha=74019.59996915652; total time=   0.0s\n",
      "[CV] END ............................alpha=74019.59996915652; total time=   0.0s\n",
      "[CV] END ............................alpha=74019.59996915652; total time=   0.0s\n",
      "[CV] END ............................alpha=74019.59996915652; total time=   0.0s\n",
      "[CV] END ............................alpha=82143.43584919439; total time=   0.0s\n",
      "[CV] END ............................alpha=82143.43584919439; total time=   0.0s\n",
      "[CV] END ............................alpha=82143.43584919439; total time=   0.0s\n",
      "[CV] END ............................alpha=82143.43584919439; total time=   0.0s\n",
      "[CV] END ............................alpha=82143.43584919439; total time=   0.0s\n",
      "[CV] END ............................alpha=91158.88299750836; total time=   0.0s\n",
      "[CV] END ............................alpha=91158.88299750836; total time=   0.0s\n",
      "[CV] END ............................alpha=91158.88299750836; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=91158.88299750836; total time=   0.0s\n",
      "[CV] END ............................alpha=91158.88299750836; total time=   0.0s\n",
      "[CV] END ............................alpha=101163.7979766207; total time=   0.0s\n",
      "[CV] END ............................alpha=101163.7979766207; total time=   0.0s\n",
      "[CV] END ............................alpha=101163.7979766207; total time=   0.0s\n",
      "[CV] END ............................alpha=101163.7979766207; total time=   0.0s\n",
      "[CV] END ............................alpha=101163.7979766207; total time=   0.0s\n",
      "[CV] END ...........................alpha=112266.77735108159; total time=   0.0s\n",
      "[CV] END ...........................alpha=112266.77735108159; total time=   0.0s\n",
      "[CV] END ...........................alpha=112266.77735108159; total time=   0.0s\n",
      "[CV] END ...........................alpha=112266.77735108159; total time=   0.0s\n",
      "[CV] END ...........................alpha=112266.77735108159; total time=   0.0s\n",
      "[CV] END ...........................alpha=124588.33642950082; total time=   0.0s\n",
      "[CV] END ...........................alpha=124588.33642950082; total time=   0.0s\n",
      "[CV] END ...........................alpha=124588.33642950082; total time=   0.0s\n",
      "[CV] END ...........................alpha=124588.33642950082; total time=   0.0s\n",
      "[CV] END ...........................alpha=124588.33642950082; total time=   0.0s\n",
      "[CV] END ............................alpha=138262.2173764659; total time=   0.0s\n",
      "[CV] END ............................alpha=138262.2173764659; total time=   0.0s\n",
      "[CV] END ............................alpha=138262.2173764659; total time=   0.0s\n",
      "[CV] END ............................alpha=138262.2173764659; total time=   0.0s\n",
      "[CV] END ............................alpha=138262.2173764659; total time=   0.0s\n",
      "[CV] END ...........................alpha=153436.84089300132; total time=   0.0s\n",
      "[CV] END ...........................alpha=153436.84089300132; total time=   0.0s\n",
      "[CV] END ...........................alpha=153436.84089300132; total time=   0.0s\n",
      "[CV] END ...........................alpha=153436.84089300132; total time=   0.0s\n",
      "[CV] END ...........................alpha=153436.84089300132; total time=   0.0s\n",
      "[CV] END ...........................alpha=170276.91722258978; total time=   0.0s\n",
      "[CV] END ...........................alpha=170276.91722258978; total time=   0.0s\n",
      "[CV] END ...........................alpha=170276.91722258978; total time=   0.0s\n",
      "[CV] END ...........................alpha=170276.91722258978; total time=   0.0s\n",
      "[CV] END ...........................alpha=170276.91722258978; total time=   0.0s\n",
      "[CV] END ...........................alpha=188965.23396912115; total time=   0.0s\n",
      "[CV] END ...........................alpha=188965.23396912115; total time=   0.0s\n",
      "[CV] END ...........................alpha=188965.23396912115; total time=   0.0s\n",
      "[CV] END ...........................alpha=188965.23396912115; total time=   0.0s\n",
      "[CV] END ...........................alpha=188965.23396912115; total time=   0.0s\n",
      "[CV] END ...........................alpha=209704.64013232305; total time=   0.0s\n",
      "[CV] END ...........................alpha=209704.64013232305; total time=   0.0s\n",
      "[CV] END ...........................alpha=209704.64013232305; total time=   0.0s\n",
      "[CV] END ...........................alpha=209704.64013232305; total time=   0.0s\n",
      "[CV] END ...........................alpha=209704.64013232305; total time=   0.0s\n",
      "[CV] END ............................alpha=232720.2478960412; total time=   0.0s\n",
      "[CV] END ............................alpha=232720.2478960412; total time=   0.0s\n",
      "[CV] END ............................alpha=232720.2478960412; total time=   0.0s\n",
      "[CV] END ............................alpha=232720.2478960412; total time=   0.0s\n",
      "[CV] END ............................alpha=232720.2478960412; total time=   0.0s\n",
      "[CV] END ...........................alpha=258261.87606826748; total time=   0.0s\n",
      "[CV] END ...........................alpha=258261.87606826748; total time=   0.0s\n",
      "[CV] END ...........................alpha=258261.87606826748; total time=   0.0s\n",
      "[CV] END ...........................alpha=258261.87606826748; total time=   0.0s\n",
      "[CV] END ...........................alpha=258261.87606826748; total time=   0.0s\n",
      "[CV] END ............................alpha=286606.7616948256; total time=   0.0s\n",
      "[CV] END ............................alpha=286606.7616948256; total time=   0.0s\n",
      "[CV] END ............................alpha=286606.7616948256; total time=   0.0s\n",
      "[CV] END ............................alpha=286606.7616948256; total time=   0.0s\n",
      "[CV] END ............................alpha=286606.7616948256; total time=   0.0s\n",
      "[CV] END ............................alpha=318062.5692794119; total time=   0.0s\n",
      "[CV] END ............................alpha=318062.5692794119; total time=   0.0s\n",
      "[CV] END ............................alpha=318062.5692794119; total time=   0.0s\n",
      "[CV] END ............................alpha=318062.5692794119; total time=   0.0s\n",
      "[CV] END ............................alpha=318062.5692794119; total time=   0.0s\n",
      "[CV] END ...........................alpha=352970.73027306574; total time=   0.0s\n",
      "[CV] END ...........................alpha=352970.73027306574; total time=   0.0s\n",
      "[CV] END ...........................alpha=352970.73027306574; total time=   0.0s\n",
      "[CV] END ...........................alpha=352970.73027306574; total time=   0.0s\n",
      "[CV] END ...........................alpha=352970.73027306574; total time=   0.0s\n",
      "[CV] END ............................alpha=391710.1490809261; total time=   0.0s\n",
      "[CV] END ............................alpha=391710.1490809261; total time=   0.0s\n",
      "[CV] END ............................alpha=391710.1490809261; total time=   0.0s\n",
      "[CV] END ............................alpha=391710.1490809261; total time=   0.0s\n",
      "[CV] END ............................alpha=391710.1490809261; total time=   0.0s\n",
      "[CV] END ............................alpha=434701.3158125035; total time=   0.0s\n",
      "[CV] END ............................alpha=434701.3158125035; total time=   0.0s\n",
      "[CV] END ............................alpha=434701.3158125035; total time=   0.0s\n",
      "[CV] END ............................alpha=434701.3158125035; total time=   0.0s\n",
      "[CV] END ............................alpha=434701.3158125035; total time=   0.0s\n",
      "[CV] END ............................alpha=482410.8704165374; total time=   0.0s\n",
      "[CV] END ............................alpha=482410.8704165374; total time=   0.0s\n",
      "[CV] END ............................alpha=482410.8704165374; total time=   0.0s\n",
      "[CV] END ............................alpha=482410.8704165374; total time=   0.0s\n",
      "[CV] END ............................alpha=482410.8704165374; total time=   0.0s\n",
      "[CV] END ............................alpha=535356.6677410719; total time=   0.0s\n",
      "[CV] END ............................alpha=535356.6677410719; total time=   0.0s\n",
      "[CV] END ............................alpha=535356.6677410719; total time=   0.0s\n",
      "[CV] END ............................alpha=535356.6677410719; total time=   0.0s\n",
      "[CV] END ............................alpha=535356.6677410719; total time=   0.0s\n",
      "[CV] END ............................alpha=594113.3984965039; total time=   0.0s\n",
      "[CV] END ............................alpha=594113.3984965039; total time=   0.0s\n",
      "[CV] END ............................alpha=594113.3984965039; total time=   0.0s\n",
      "[CV] END ............................alpha=594113.3984965039; total time=   0.0s\n",
      "[CV] END ............................alpha=594113.3984965039; total time=   0.0s\n",
      "[CV] END ............................alpha=659318.8271333541; total time=   0.0s\n",
      "[CV] END ............................alpha=659318.8271333541; total time=   0.0s\n",
      "[CV] END ............................alpha=659318.8271333541; total time=   0.0s\n",
      "[CV] END ............................alpha=659318.8271333541; total time=   0.0s\n",
      "[CV] END ............................alpha=659318.8271333541; total time=   0.0s\n",
      "[CV] END ............................alpha=731680.7143427207; total time=   0.0s\n",
      "[CV] END ............................alpha=731680.7143427207; total time=   0.0s\n",
      "[CV] END ............................alpha=731680.7143427207; total time=   0.0s\n",
      "[CV] END ............................alpha=731680.7143427207; total time=   0.0s\n",
      "[CV] END ............................alpha=731680.7143427207; total time=   0.0s\n",
      "[CV] END ............................alpha=811984.4993184009; total time=   0.0s\n",
      "[CV] END ............................alpha=811984.4993184009; total time=   0.0s\n",
      "[CV] END ............................alpha=811984.4993184009; total time=   0.0s\n",
      "[CV] END ............................alpha=811984.4993184009; total time=   0.0s\n",
      "[CV] END ............................alpha=811984.4993184009; total time=   0.0s\n",
      "[CV] END ............................alpha=901101.8251665037; total time=   0.0s\n",
      "[CV] END ............................alpha=901101.8251665037; total time=   0.0s\n",
      "[CV] END ............................alpha=901101.8251665037; total time=   0.0s\n",
      "[CV] END ............................alpha=901101.8251665037; total time=   0.0s\n",
      "[CV] END ............................alpha=901101.8251665037; total time=   0.0s\n",
      "[CV] END ....................................alpha=1000000.0; total time=   0.0s\n",
      "[CV] END ....................................alpha=1000000.0; total time=   0.0s\n",
      "[CV] END ....................................alpha=1000000.0; total time=   0.0s\n",
      "[CV] END ....................................alpha=1000000.0; total time=   0.0s\n",
      "[CV] END ....................................alpha=1000000.0; total time=   0.0s\n",
      "Régression <class 'sklearn.linear_model._coordinate_descent.Lasso'> train set score R2: 0.88, MAE: 3.29, mean_squared_error: 93.65\n",
      "Régression <class 'sklearn.linear_model._coordinate_descent.Lasso'> test set score R2: 0.96, MAE: 2.84, mean_squared_error: 25.34\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estLA, y_pred,LA,mae_LA)=regression(Lasso,{'alpha':np.logspace(-3, 6, 200)})\n",
    "time_LA=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae32eb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(Lasso,estLA)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4b63de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._coordinate_descent.Lasso'> picked 8 features and eliminated the other 9 features\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1=plt.subplot(121)\n",
    "coef(estLA,Lasso)\n",
    "ax2=plt.subplot(122)\n",
    "evo(Lasso)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b24f4b8",
   "metadata": {},
   "source": [
    "## <a name=\"C14\">4-1-4 Régularisation ElasticNet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8772c43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.681e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.682e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.165e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.683e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0011097524964120721, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.719e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0012315506032928262, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.722e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.210e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.688e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.001366716356462006, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.691e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.692e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0015167168884709225, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.726e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.266e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.695e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0016831803533309566, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.298e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.698e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0018679135990207828, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.732e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.334e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.734e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.701e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.702e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.735e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.374e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002072921779595372, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.705e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.706e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002300430119772917, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.418e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.709e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.711e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0025529080682395165, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.748e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.748e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.002833096101839324, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.521e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.722e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.0031440354715915, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.760e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.726e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.728e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..........alpha=0.0034891012134067737, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.767e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.733e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.003872038781812557, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.764e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.775e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.771e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004297004704320844, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.803e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.749e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.752e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.004768611697714469, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.778e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.793e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.762e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.787e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005291978735958442, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.993e+03, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.772e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.005872786613189483, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.815e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.784e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.806e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00651733960488242, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.793e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.817e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.842e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.007232633896483534, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.807e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.811e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.008026433522257174, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.857e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.822e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.844e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.874e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.00890735463861044, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.839e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.844e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.009884959046625586, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.893e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.857e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.863e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.876e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.010969857978923836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.884e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.012173827277396614, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.936e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.901e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.915e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.013509935211980273, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.926e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.014992684327860457, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.01663816886076129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.992e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.018464249428955443, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.991e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.053e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.017e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.026e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.021e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.020490746898158472, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.054e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.064e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.055e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.022739657523579287, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.131e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.094e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.105e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02523539170434766, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.093e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.175e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.139e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.150e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.134e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.02800503894183631, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.224e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.187e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.200e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03107866187782014, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.179e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.277e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.241e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.229e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.03448962260405758, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.300e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.038274944785163134, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.284e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.399e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.364e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.379e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.344e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.04247571552536898, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.470e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.450e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...........alpha=0.047137531341167244, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.411e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.546e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.528e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.484e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05231099308056263, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.630e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.597e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.614e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.05805225516094899, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.564e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.722e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.690e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.708e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.06442363508721373, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.791e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07149428986597581, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.810e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.931e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.901e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.921e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.854e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.07934096665797492, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.050e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.08804883581643465, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.043e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.970e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.179e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.153e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.176e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.096e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.09771241535346502, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.320e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.296e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.320e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.234e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.720e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.1084365968689611, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.452e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.477e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.384e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.12033778407775893, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.640e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.621e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.648e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.547e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.13354515629298988, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.805e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.833e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.725e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.14820207057988585, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.015e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.003e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.034e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.918e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.16446761779946645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.218e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.251e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.127e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.18251834943190443, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.766e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.454e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.449e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.485e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.20255019392306664, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.353e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.029e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.699e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.698e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.738e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.597e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.312e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.22478058335487253, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.962e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.966e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.009e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.859e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.24945081352303167, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.616e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.253e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.300e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.140e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.941e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.27682866303920667, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.546e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.560e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.612e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.442e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.289e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.868e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3072112998861759, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.888e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.944e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.764e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ............alpha=0.34092850697468147, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.659e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.236e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.299e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.108e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.052e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.3783462617131929, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.605e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.675e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.473e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.468e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.958e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.419870708444391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.073e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.859e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.4659525668664682, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.907e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.363e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.493e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.267e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.369e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.789e+04, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.837e+04, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=0.517092024289676, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.934e+04, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.696e+04, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.5738441648302398, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.6368249944718586, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.358e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7067181273927491, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.884e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.7842822061337682, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.429e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.991e+04, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.8703591361485166, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=0.9658832241158708, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.0718913192051276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.1895340673703196, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.3200884008314182, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.4649713983072863, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1.625755666443795, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1.8041864093920719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.0022003718155843, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.2219468609395236, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2.4658110758226037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2.736439997074672, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3.0367711180354604, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.370064329271928, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=3.739937302478798, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.040e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.150404757850477, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4.605922041145108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=5.1114334834401705, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.982e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5.672426068491977, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.294988990221888, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6.985879746785249, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=7.752597488629465, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=8.60346441668451, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.380e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=9.547716114208066, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=10.59560179277617, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=11.758495540521581, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11.758495540521581, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=13.049019780144016, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13.049019780144016, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=14.481182276745331, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=14.481182276745331, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=14.481182276745331, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=16.070528182616385, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=16.070528182616385, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=17.834308769319094, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17.834308769319094, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.377e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=19.791668678535572, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.396e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=19.791668678535572, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19.791668678535572, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21.96385372416547, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.599e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=24.37444150122222, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=27.04959730463137, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=30.01835813575592, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=33.31294787934677, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=36.96912707195032, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.568e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=41.0265810582719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.627e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=45.52935074866948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.684e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=50.526310653356795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=50.526310653356795, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=56.07169938205458, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=62.22570836730231, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=69.0551352016233, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.539e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=76.63410868007462, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=85.04489341802686, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.670e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=94.37878277775391, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.549e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=104.73708979594508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=104.73708979594508, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=116.23224686798542, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=116.23224686798542, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=116.23224686798542, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.682e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=128.9890261253308, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=143.14589375234786, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=143.14589375234786, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.743e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=158.85651294280527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.695e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.691e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=158.85651294280527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=158.85651294280527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.641e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=176.2914118095948, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=195.63983435170647, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=195.63983435170647, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=195.63983435170647, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=217.11179456945052, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=217.11179456945052, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=217.11179456945052, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=240.9403560239527, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=267.38416158399497, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=267.38416158399497, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=267.38416158399497, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=296.73024081888724, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=296.73024081888724, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.703e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=329.2971255097155, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=365.43830709572546, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=365.43830709572546, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=405.54607358408276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=405.54607358408276, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=405.54607358408276, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=450.05576757004974, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=450.05576757004974, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=499.450511585514, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=499.450511585514, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=499.450511585514, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.763e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=554.2664520663108, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=615.0985788580505, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=682.6071834272393, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=757.525025877192, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=757.525025877192, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=840.6652885618333, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=932.9304026284696, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1035.3218432956637, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1148.9510001873086, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.720e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1275.051240713013, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.720e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1414.991297434576, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.720e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1570.2901247293776, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=1742.6333860096508, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=1933.891750455232, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=2146.141197858406, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2381.6855519761607, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2643.0814869741084, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=2933.1662783900483, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3255.0885998350564, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=3612.3426997094302, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=4008.8063288984645, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4448.782831127585, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=4937.047852839004, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=5478.901179593945, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=6080.224261649427, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=6747.5440531107, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=6747.5440531107, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ................alpha=6747.5440531107, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=7488.10385759003, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=8309.941949353404, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ...............alpha=9221.97882333434, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=10234.114021054527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=10234.114021054527, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=10234.114021054527, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=11357.333583431051, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=11357.333583431051, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=12603.829296797274, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=12603.829296797274, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=12603.829296797274, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=13987.131026472387, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=13987.131026472387, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=15522.25357427048, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=17225.859653987874, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=17225.859653987874, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=17225.859653987874, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=19116.440753857038, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=19116.440753857038, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=19116.440753857038, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=21214.51784910632, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=23542.864143224204, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=23542.864143224204, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=23542.864143224204, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=26126.752255633317, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=26126.752255633317, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=28994.22853882881, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=32176.417502507353, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=32176.417502507353, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=32176.417502507353, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=35707.859649004626, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=35707.859649004626, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=39626.88638701478, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=43976.036093027215, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=43976.036093027215, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=48802.515836544335, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=48802.515836544335, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=48802.515836544335, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=54158.71378079476, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=60102.76782070388, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=66699.19663030129, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=74019.59996915652, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=82143.43584919439, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=91158.88299750836, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=101163.7979766207, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=112266.77735108159, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=112266.77735108159, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=112266.77735108159, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=124588.33642950082, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=124588.33642950082, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=138262.2173764659, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=153436.84089300132, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=153436.84089300132, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=170276.91722258978, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=170276.91722258978, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=170276.91722258978, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=188965.23396912115, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=188965.23396912115, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=209704.64013232305, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=209704.64013232305, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=209704.64013232305, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=232720.2478960412, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=258261.87606826748, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=258261.87606826748, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=258261.87606826748, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=286606.7616948256, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=318062.5692794119, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=352970.73027306574, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=352970.73027306574, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END .............alpha=352970.73027306574, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=391710.1490809261, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=434701.3158125035, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=482410.8704165374, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=535356.6677410719, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=594113.3984965039, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=0.0; total time=   0.1s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=659318.8271333541, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=731680.7143427207, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=811984.4993184009, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=0.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ..............alpha=901101.8251665037, l1_ratio=1.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+05, tolerance: 5.188e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+05, tolerance: 5.434e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+05, tolerance: 5.330e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................alpha=1000000.0, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=0.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=1.0; total time=   0.0s\n",
      "[CV] END ......................alpha=1000000.0, l1_ratio=1.0; total time=   0.0s\n",
      "Régression <class 'sklearn.linear_model._coordinate_descent.ElasticNet'> train set score R2: 0.88, MAE: 3.29, mean_squared_error: 93.65\n",
      "Régression <class 'sklearn.linear_model._coordinate_descent.ElasticNet'> test set score R2: 0.96, MAE: 2.84, mean_squared_error: 25.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+05, tolerance: 5.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+05, tolerance: 5.447e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estEN, y_pred,EN,mae_EN)=regression(ElasticNet,{'l1_ratio':np.linspace(0,1,2),'alpha':np.logspace(-3, 6, 200)})\n",
    "time_EN=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0a7b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(ElasticNet,estEN)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf9d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._coordinate_descent.ElasticNet'> picked 8 features and eliminated the other 9 features\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1=plt.subplot(121)\n",
    "coef(estEN,ElasticNet)\n",
    "ax2=plt.subplot(122)\n",
    "evo(ElasticNet)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdea9a54",
   "metadata": {},
   "source": [
    "## <a name=\"C15\">4-1-5 Régression KNN</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a1b5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
      "[CV] END ......................................n_neighbors=1; total time=   0.3s\n",
      "[CV] END ......................................n_neighbors=1; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=1; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=1; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=1; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=2; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=2; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=2; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=2; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=2; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=4; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=4; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=4; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=4; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=4; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=6; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=6; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=6; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=6; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=6; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=8; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=8; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=8; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=8; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=8; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=9; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=9; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=9; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=9; total time=   0.0s\n",
      "[CV] END ......................................n_neighbors=9; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=11; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=11; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=11; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=11; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=11; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=12; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=12; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=12; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=12; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=12; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=13; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=13; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=13; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=13; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=13; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=14; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=14; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=14; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=14; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=14; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=15; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=15; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=15; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=15; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=15; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=16; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=16; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=16; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=16; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=16; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=17; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=17; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=17; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=17; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=17; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=18; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=18; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=18; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=18; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=18; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=19; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=19; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=19; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=19; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=19; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=20; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=20; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=20; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=20; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=20; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=21; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=21; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=21; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=21; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=21; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=22; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=22; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=22; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=22; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=22; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=23; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=23; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=23; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=23; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................................n_neighbors=23; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=24; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=24; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=24; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=24; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=24; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=25; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=25; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=25; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=25; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=25; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=26; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=26; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=26; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=26; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=26; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=27; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=27; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=27; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=27; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=27; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=28; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=28; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=28; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=28; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=28; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=29; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=29; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=29; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=29; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=29; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=30; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=30; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=30; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=30; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=30; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=31; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=31; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=31; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=31; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=31; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=32; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=32; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=32; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=32; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=32; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=33; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=33; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=33; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=33; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=33; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=34; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=34; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=34; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=34; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=34; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=35; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=35; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=35; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=35; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=35; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=36; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=36; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=36; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=36; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=36; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=37; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=37; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=37; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=37; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=37; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=38; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=38; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=38; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=38; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=38; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=39; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=39; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=39; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=39; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=39; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=40; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=40; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=40; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=40; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=40; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=41; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=41; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=41; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=41; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=41; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=42; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=42; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=42; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=42; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=42; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=43; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=43; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=43; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=43; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=43; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=44; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=44; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=44; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=44; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=44; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=45; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=45; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=45; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................................n_neighbors=45; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=45; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=46; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=46; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=46; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=46; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=46; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=47; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=47; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=47; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=47; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=47; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=48; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=48; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=48; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=48; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=48; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=49; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=49; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=49; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=49; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=49; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=50; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=50; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=50; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=50; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=50; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=51; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=51; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=51; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=51; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=51; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=52; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=52; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=52; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=52; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=52; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=53; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=53; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=53; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=53; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=53; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=54; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=54; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=54; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=54; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=54; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=55; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=55; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=55; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=55; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=55; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=56; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=56; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=56; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=56; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=56; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=57; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=57; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=57; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=57; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=57; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=58; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=58; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=58; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=58; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=58; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=59; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=59; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=59; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=59; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=59; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=60; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=60; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=60; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=60; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=60; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=61; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=61; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=61; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=61; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=61; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=62; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=62; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=62; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=62; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=62; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=63; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=63; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=63; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=63; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=63; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=64; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=64; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=64; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=64; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=64; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=65; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=65; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=65; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=65; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=65; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=66; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................................n_neighbors=66; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=66; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=66; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=66; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=67; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=67; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=67; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=67; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=67; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=68; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=68; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=68; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=68; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=68; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=69; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=69; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=69; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=69; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=69; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=70; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=70; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=70; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=70; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=70; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=71; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=71; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=71; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=71; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=71; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=72; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=72; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=72; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=72; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=72; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=73; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=73; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=73; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=73; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=73; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=74; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=74; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=74; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=74; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=74; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=75; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=75; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=75; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=75; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=75; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=76; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=76; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=76; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=76; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=76; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=77; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=77; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=77; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=77; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=77; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=78; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=78; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=78; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=78; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=78; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=79; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=79; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=79; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=79; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=79; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=80; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=80; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=80; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=80; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=80; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=81; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=81; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=81; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=81; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=81; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=82; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=82; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=82; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=82; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=82; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=83; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=83; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=83; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=83; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=83; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=84; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=84; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=84; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=84; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=84; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=85; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=85; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=85; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=85; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=85; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=86; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=86; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=86; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=86; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=86; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=87; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=87; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=87; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=87; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=87; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................................n_neighbors=88; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=88; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=88; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=88; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=88; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=89; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=89; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=89; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=89; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=89; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=90; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=90; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=90; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=90; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=90; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=91; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=91; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=91; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=91; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=91; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=92; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=92; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=92; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=92; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=92; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=93; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=93; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=93; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=93; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=93; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=94; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=94; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=94; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=94; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=94; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=95; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=95; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=95; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=95; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=95; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=96; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=96; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=96; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=96; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=96; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=97; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=97; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=97; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=97; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=97; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=98; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=98; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=98; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=98; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=98; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=99; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=99; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=99; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=99; total time=   0.0s\n",
      "[CV] END .....................................n_neighbors=99; total time=   0.0s\n",
      "Régression <class 'sklearn.neighbors._regression.KNeighborsRegressor'> train set score R2: 0.85, MAE: 7.08, mean_squared_error: 115.57\n",
      "Régression <class 'sklearn.neighbors._regression.KNeighborsRegressor'> test set score R2: 0.75, MAE: 9.26, mean_squared_error: 160.66\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estKN, y_pred,KN,mae_KN)=regression(KNeighborsRegressor,{\"n_neighbors\": range(1,100)})\n",
    "time_KN=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da2bc93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(KNeighborsRegressor,estKN)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b590be10",
   "metadata": {},
   "source": [
    "## <a name=\"C16\">4-1-6 Régression Kernel SVR</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b4dd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.0001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.0001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.0001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.0001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.0001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.0001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.0001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.0001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.0001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.0001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.0001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.0001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.0001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.0001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.0001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.0001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.0001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.0001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.0001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END C=0.001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END C=0.001, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.001, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.1s\n",
      "[CV] END .....C=0.001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.001, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.001, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.001, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.001, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.001, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.001, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.001, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.001, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.001, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.001, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.001, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.01, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.01, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .C=0.01, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.01, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.01, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.01, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .C=0.01, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.01, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.01, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.01, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.01, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.01, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.01, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.01, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.01, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.01, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.01, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.01, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.01, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.01, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.01, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.01, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.01, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.01, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.01, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.01, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.01, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=0.1, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=0.1, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=0.1, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.1, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.1, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=0.1, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.1, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.1, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.1, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=0.1, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.1, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=0.1, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=0.1, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=0.1, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=0.1, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=0.1, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=0.1, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=0.1, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=0.1, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=0.1, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=0.1, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=1.0, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=1.0, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=0, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1.0, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=0, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=1.0, epsilon=0.01, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ..C=1.0, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=1.0, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=1.0, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..C=1.0, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=1.0, epsilon=0.01, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.01, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.01, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.01, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=1.0, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.01, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=1.0, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=1.0, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=1.0, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ....C=1.0, epsilon=0.5, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=1.0, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...C=1.0, epsilon=0.5, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=1.0, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=0.5, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=0.5, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=1.0, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=0.5, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=0.5, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=1, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=1, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1.0, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=1, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=1, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=1, kernel=rbf, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1.0, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=1, kernel=rbf, max_iter=1000; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=1.0, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=linear, max_iter=10; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END ......C=1.0, epsilon=2, kernel=linear, max_iter=100; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .....C=1.0, epsilon=2, kernel=linear, max_iter=1000; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=poly, max_iter=10; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1.0, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=poly, max_iter=100; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END .......C=1.0, epsilon=2, kernel=poly, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........C=1.0, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END ..........C=1.0, epsilon=2, kernel=rbf, max_iter=10; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END .........C=1.0, epsilon=2, kernel=rbf, max_iter=100; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "[CV] END ........C=1.0, epsilon=2, kernel=rbf, max_iter=1000; total time=   0.0s\n",
      "Régression <class 'sklearn.svm._classes.SVR'> train set score R2: 0.88, MAE: 2.70, mean_squared_error: 95.05\n",
      "Régression <class 'sklearn.svm._classes.SVR'> test set score R2: 0.96, MAE: 2.32, mean_squared_error: 24.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estSV, y_pred,SV,mae_SV)=regression(SVR,{'kernel':['linear', 'poly', 'rbf'],'C' : np.logspace(-4, 0, 5),\n",
    "             'epsilon' : [0, 0.01, 0.1, 0.5, 1, 2],\n",
    "             'max_iter': [10, 100, 1000]})\n",
    "time_SV=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5569b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(SVR,estSV)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9613200a",
   "metadata": {},
   "source": [
    "## <a name=\"C17\">4-1-7 XGboost</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91651520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[15:50:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:50:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:50:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:02] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:05] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:08] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:08] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.8s\n",
      "[15:51:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   1.1s\n",
      "[15:51:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.9s\n",
      "[15:51:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:17] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.8s\n",
      "[15:51:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.8s\n",
      "[15:51:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.8s\n",
      "[15:51:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:22] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.5s\n",
      "[15:51:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.9s\n",
      "[15:51:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.6s\n",
      "[15:51:29] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:29] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.7s\n",
      "[15:51:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:33] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[15:51:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "Régression <class 'xgboost.sklearn.XGBRegressor'> train set score R2: 0.98, MAE: 1.68, mean_squared_error: 17.48\n",
      "Régression <class 'xgboost.sklearn.XGBRegressor'> test set score R2: 0.95, MAE: 3.59, mean_squared_error: 30.12\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estXG, y_pred,XG,mae_XG)=regression(XGBRegressor,{'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]})\n",
    "time_XG=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b6190f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(XGBRegressor,estXG)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bb4cb7f",
   "metadata": {},
   "source": [
    "## <a name=\"C18\">4-1-8 Random Forest</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d5cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END .................................................... total time=   1.1s\n",
      "[CV] END .................................................... total time=   1.1s\n",
      "[CV] END .................................................... total time=   1.1s\n",
      "[CV] END .................................................... total time=   1.6s\n",
      "[CV] END .................................................... total time=   1.4s\n",
      "Régression <class 'sklearn.ensemble._forest.RandomForestRegressor'> train set score R2: 0.97, MAE: 1.50, mean_squared_error: 23.90\n",
      "Régression <class 'sklearn.ensemble._forest.RandomForestRegressor'> test set score R2: 0.92, MAE: 3.52, mean_squared_error: 47.75\n"
     ]
    }
   ],
   "source": [
    "time_1=time.time()\n",
    "(estRF, y_pred,RF,mae_RF)=regression(RandomForestRegressor,{})\n",
    "time_RF=time.time()-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b095eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "y_pred_t=plot_a(RandomForestRegressor,estRF)\n",
    "\n",
    "ax2= plt.subplot(122)\n",
    "plot_b(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2516378e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.014 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "start_time = time.time()\n",
    "importances = estRF.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in estRF.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18af3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest_importances = pd.Series(importances, index=X.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441235ed",
   "metadata": {},
   "source": [
    "## <a name=\"C19\">4-1-9 Synthèse modèle prédictif ‘SiteEnergyUseWN(kBtu)/sf’</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c66c0ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n",
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3128175340.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ss= ss.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>meilleurs_paramètres</th>\n",
       "      <th>meilleur_score</th>\n",
       "      <th>process_time</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyRegressor()</td>\n",
       "      <td>{'strategy': 'mean'}</td>\n",
       "      <td>-0.010691</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>19.934615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KernelRidge()</td>\n",
       "      <td>{'alpha': 1.4649713983072863, 'gamma': 0.01, '...</td>\n",
       "      <td>0.877331</td>\n",
       "      <td>335.184967</td>\n",
       "      <td>3.409124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>{'alpha': 0.34092850697468147}</td>\n",
       "      <td>0.885343</td>\n",
       "      <td>3.528304</td>\n",
       "      <td>2.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>{'alpha': 0.34092850697468147, 'l1_ratio': 1.0}</td>\n",
       "      <td>0.885343</td>\n",
       "      <td>74.455721</td>\n",
       "      <td>2.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.747340</td>\n",
       "      <td>9.096130</td>\n",
       "      <td>9.263331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 2, 'kernel': 'linear', '...</td>\n",
       "      <td>0.888564</td>\n",
       "      <td>27.393992</td>\n",
       "      <td>2.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'learning_rate': 0.0...</td>\n",
       "      <td>0.846288</td>\n",
       "      <td>36.359100</td>\n",
       "      <td>3.586925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.850774</td>\n",
       "      <td>10.291735</td>\n",
       "      <td>3.518883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modèle  \\\n",
       "0                                   DummyRegressor()   \n",
       "1                                      KernelRidge()   \n",
       "2                                            Lasso()   \n",
       "3                                       ElasticNet()   \n",
       "4                              KNeighborsRegressor()   \n",
       "5                                              SVR()   \n",
       "6  XGBRegressor(base_score=None, booster=None, ca...   \n",
       "7                            RandomForestRegressor()   \n",
       "\n",
       "                                meilleurs_paramètres  meilleur_score  \\\n",
       "0                               {'strategy': 'mean'}       -0.010691   \n",
       "1  {'alpha': 1.4649713983072863, 'gamma': 0.01, '...        0.877331   \n",
       "2                     {'alpha': 0.34092850697468147}        0.885343   \n",
       "3    {'alpha': 0.34092850697468147, 'l1_ratio': 1.0}        0.885343   \n",
       "4                                 {'n_neighbors': 4}        0.747340   \n",
       "5  {'C': 1.0, 'epsilon': 2, 'kernel': 'linear', '...        0.888564   \n",
       "6  {'colsample_bytree': 0.7, 'learning_rate': 0.0...        0.846288   \n",
       "7                                                 {}        0.850774   \n",
       "\n",
       "   process_time        MAE  \n",
       "0      0.015956  19.934615  \n",
       "1    335.184967   3.409124  \n",
       "2      3.528304   2.841370  \n",
       "3     74.455721   2.841370  \n",
       "4      9.096130   9.263331  \n",
       "5     27.393992   2.322960  \n",
       "6     36.359100   3.586925  \n",
       "7     10.291735   3.518883  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tableau récapitulatif des résultats par modèle\n",
    "ss=pd.DataFrame(columns=['modèle','meilleurs_paramètres', 'meilleur_score', 'process_time'])\n",
    "dic={AN:[time_AN,mae_AN],\n",
    "     KR:[time_KR,mae_KR],\n",
    "     LA:[time_LA,mae_LA],\n",
    "     EN:[time_EN,mae_EN],\n",
    "     KN:[time_KN,mae_KN],\n",
    "     SV:[time_SV,mae_SV],\n",
    "     XG:[time_XG,mae_XG],\n",
    "     RF:[time_RF,mae_RF]}\n",
    "for model in [AN,KR,LA,EN,KN,SV,XG,RF]: \n",
    "    new_row = {'modèle':model.estimator, \n",
    "               'meilleurs_paramètres':model.best_params_, \n",
    "               'meilleur_score':model.best_score_, \n",
    "               'MAE':dic[model][1],\n",
    "               'process_time':dic[model][0]}\n",
    "\n",
    "    ss= ss.append(new_row, ignore_index=True)\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c877b",
   "metadata": {},
   "source": [
    "## <a href=\"#A7\">**Partie 5 : Comparaison avec/sans la variable 'EnergyStar'**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4cb9f",
   "metadata": {},
   "source": [
    "## On ajoute la colonne EnergyScore à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efa63ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df33d=pd.read_csv('df33d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7512cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\category_encoders\\target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\category_encoders\\target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "df35=df33d.copy()\n",
    "\n",
    "[i for i in df35.columns if df35[i].dtype=='object']\n",
    "\n",
    "#on targetencode les colonnes catégorielles\n",
    "Target = 'SiteEnergyUseWN(kBtu)/sf'\n",
    "encoder = TargetEncoder()\n",
    "for i in [i for i in df35.columns if df35[i].dtype=='object']:\n",
    "    df35[i] = encoder.fit_transform(df35[i], df35[Target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8a231",
   "metadata": {},
   "source": [
    "## 'SiteEnergyUseWN(kBtu)/sf': On applique le modèle avec EnergyStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc14201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 18)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df35.columns if i.endswith('sf')==True]\n",
    "\n",
    "#transformons les data en X et y (SiteEnergyUse(kBtu))\n",
    "df35.dropna(axis='rows', how='any',inplace=True)\n",
    "X=df35.drop(columns=['SiteEnergyUseWN(kBtu)/sf',\n",
    "            'TotalGHGEmissions/sf',\n",
    "            'GHGEmissionsIntensity/sf'\n",
    "                    ]\n",
    "           )\n",
    "y=df35['SiteEnergyUseWN(kBtu)/sf'].values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "258adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#découpons en train et test samplefrom sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.2, # 30% des données dans le jeu de test\n",
    "                                   random_state=42)\n",
    "\n",
    "#standardisons X_train et X_test\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4f3f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Régression SVR train set Mean score R2: 0.79, MAE: 2.72, mean_squared_error: 124.69\n",
      "Régression SVR test set Mean score R2: 0.96, MAE: 2.45, mean_squared_error: 29.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Entraînement du modèle avec les paramètres optimum sur tout le train set\n",
    "estSV = SVR(kernel='linear',\n",
    "            C=1,\n",
    "            epsilon=1,\n",
    "            max_iter=1000)\n",
    "estSV.fit(X_train_std, y_train)\n",
    "\n",
    "#Prédiction sur le test set\n",
    "y_pred = estSV.predict(X_test_std)\n",
    "\n",
    "#Compraison des scores train et test set\n",
    "print('Régression SVR train set Mean score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "      .format(r2_score(y_train, estSV.predict(X_train_std)),mean_absolute_error(y_train, estSV.predict(X_train_std)),\n",
    "              mean_squared_error(y_train, estSV.predict(X_train_std))))\n",
    "print('Régression SVR test set Mean score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "      .format(r2_score(y_test, y_pred),mean_absolute_error(y_test, y_pred),\n",
    "              mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cc12b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\2887751889.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ssi= ssi.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>meilleur_score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR(C=1, epsilon=1, kernel='linear', max_iter=...</td>\n",
       "      <td>0.961416</td>\n",
       "      <td>2.447796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modèle  meilleur_score       MAE\n",
       "0  SVR(C=1, epsilon=1, kernel='linear', max_iter=...        0.961416  2.447796"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tableau récapitulatif des résultats avec EnergyStar\n",
    "ssi=pd.DataFrame(columns=['modèle','meilleur_score','MAE'])\n",
    "\n",
    "for model in [estSV]:    \n",
    "    new_row = {'modèle':model, \n",
    "               'meilleur_score':r2_score(y_test, y_pred), \n",
    "               'MAE':mean_absolute_error(y_test, y_pred)\n",
    "              }\n",
    "    \n",
    "    ssi= ssi.append(new_row, ignore_index=True)\n",
    "ssi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83726a9",
   "metadata": {},
   "source": [
    "## 'SiteEnergyUseWN(kBtu)/sf' : On applique le modèle sans EnergyStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "394ff7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 17)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df35.columns if i.endswith('sf')==True]\n",
    "\n",
    "#transformons les data en X et y (SiteEnergyUse(kBtu))\n",
    "df35.dropna(axis='rows', how='any',inplace=True)\n",
    "X=df35.drop(columns=['SiteEnergyUseWN(kBtu)/sf',\n",
    "            'ENERGYSTARScore',\n",
    "            'TotalGHGEmissions/sf',\n",
    "            'GHGEmissionsIntensity/sf'\n",
    "                    ]\n",
    "           )\n",
    "y=df35['SiteEnergyUseWN(kBtu)/sf'].values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "165502d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#découpons en train et test sample\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.2, # 30% des données dans le jeu de test\n",
    "                                    random_state=42)\n",
    "\n",
    "#standardisons X_train et X_test\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42373562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Formation\\4-Anticipez les besoins en consommation de bâtiments\\1-Projet\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Régression SVR train set Mean score R2: 0.79, MAE: 2.71, mean_squared_error: 123.98\n",
      "Régression SVR test set Mean score R2: 0.96, MAE: 2.44, mean_squared_error: 29.65\n"
     ]
    }
   ],
   "source": [
    "#Entraînement du modèle avec les paramètres optimum sur tout le train set\n",
    "estSV = SVR(kernel='linear',\n",
    "            C=1,\n",
    "            epsilon=1,\n",
    "            max_iter=1000)\n",
    "estSV.fit(X_train_std, y_train)\n",
    "\n",
    "#Prédiction sur le test set\n",
    "y_pred = estSV.predict(X_test_std)\n",
    "\n",
    "#Compraison des scores train et test set\n",
    "print('Régression SVR train set Mean score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "      .format(r2_score(y_train, estSV.predict(X_train_std)),mean_absolute_error(y_train, estSV.predict(X_train_std)),\n",
    "              mean_squared_error(y_train, estSV.predict(X_train_std))))\n",
    "print('Régression SVR test set Mean score R2: {:.2f}, MAE: {:.2f}, mean_squared_error: {:.2f}'\n",
    "      .format(r2_score(y_test, y_pred),mean_absolute_error(y_test, y_pred),\n",
    "              mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "745ee801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp\\ipykernel_12036\\3565784030.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ssf= ssf.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>meilleur_score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR(C=1, epsilon=1, kernel='linear', max_iter=...</td>\n",
       "      <td>0.96167</td>\n",
       "      <td>2.440505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modèle  meilleur_score       MAE\n",
       "0  SVR(C=1, epsilon=1, kernel='linear', max_iter=...         0.96167  2.440505"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tableau récapitulatif des résultats sans EnergyStar\n",
    "ssf=pd.DataFrame(columns=['modèle','meilleur_score','MAE'])\n",
    "for model in [estSV]:    \n",
    "    new_row = {'modèle':model, \n",
    "               'meilleur_score':r2_score(y_test, y_pred), \n",
    "               'MAE':mean_absolute_error(y_test, y_pred)\n",
    "              }\n",
    "\n",
    "    ssf= ssf.append(new_row, ignore_index=True)\n",
    "ssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75ddafa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour la target SiteEnergyUseWN(kBtu)/sf la variable EnergyStar améliore le score du modèle de 0.73 %\n"
     ]
    }
   ],
   "source": [
    "## Bilan\n",
    "print(f'Pour la target SiteEnergyUseWN(kBtu)/sf la variable EnergyStar améliore le score du modèle de {round((ssi.iloc[0,2]-ssf.iloc[0,2])*100,2)} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
